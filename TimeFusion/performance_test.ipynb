{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601200000.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t2.timestamp()*1000) % (t3.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604800000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t3.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27976190476190477"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "t2 = datetime(year=2000,month=10,day=7)\n",
    "t3 = timedelta(weeks=1)\n",
    "\n",
    "((t2.timestamp()*1000) % (t3.total_seconds()*1000))/(t3.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta(milliseconds=1).total_seconds()*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([True,True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.ones([2,5,4,6], dtype=torch.float64, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape[:-1] + tuple([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({1,2,3,5,6,6,7,89,0} - {3,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,:,list({1,0})].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 6, 7, 89]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({1,2,3,5,6,6,7,89,0} - {3,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,:,:1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00, -2.4493e-16,\n",
       "        -2.4493e-16,  1.0000e+00,  1.0000e+00,  6.2831e-03,  6.2831e-03,\n",
       "         9.9998e-01,  9.9998e-01,  1.0472e-04,  1.0472e-04,  1.0000e+00,\n",
       "         1.0000e+00,  7.2722e-08,  7.2722e-08,  1.0000e+00,  1.0000e+00,\n",
       "         1.0389e-08,  1.0389e-08,  1.0000e+00,  1.0000e+00,  2.4241e-09,\n",
       "         2.4241e-09,  1.0000e+00,  1.0000e+00,  1.9924e-10,  1.9924e-10,\n",
       "         1.0000e+00,  1.0000e+00,  1.9924e-11,  1.9924e-11,  1.0000e+00,\n",
       "         1.0000e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timefusion import PositionalEncoding\n",
    "import torch\n",
    "\n",
    "out = torch.ones([2,5,4,6], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "k = PositionalEncoding(6,[],[2,5])\n",
    "\n",
    "k(out)[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones([\u001b[39m32\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m6\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m k0 \u001b[39m=\u001b[39m PositionalEncoding(\u001b[39m6\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,[\u001b[39m2\u001b[39;49m],[\u001b[39m4\u001b[39;49m],num_sines\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m k1 \u001b[39m=\u001b[39m Embedding(k0\u001b[39m.\u001b[39mencoding_dim,\u001b[39m3\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m out \u001b[39m=\u001b[39m k0(out)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/timefusion.py:112\u001b[0m, in \u001b[0;36mPositionalEncoding.__init__\u001b[0;34m(self, datapoint_dim, indices, timestamps, device, num_sines, time_per)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# Assertions to ensure correct usage\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39massert\u001b[39;00m num_sines \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnum_sines\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be an even number\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39;49m(\u001b[39m0\u001b[39;49m \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m idx \u001b[39m<\u001b[39;49m datapoint_dim \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m indices), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindices\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m datapoint_dim \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m timestamps), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimestamps\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Init nn.Module base class\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/timefusion.py:112\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# Assertions to ensure correct usage\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39massert\u001b[39;00m num_sines \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnum_sines\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be an even number\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m datapoint_dim \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindices\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m datapoint_dim \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m timestamps), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimestamps\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Init nn.Module base class\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "from timefusion import Embedding, PositionalEncoding\n",
    "import torch\n",
    "\n",
    "out = torch.ones([32,100,100,6], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "k0 = PositionalEncoding(6,\"cpu\",[2],[4],num_sines=20)\n",
    "k1 = Embedding(k0.encoding_dim,3,\"cpu\")\n",
    "\n",
    "out = k0(out)\n",
    "out = k1(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in k0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7064, -1.5153, -1.6143,  ..., -1.4957, -1.4604, -1.5956],\n",
       "         [-1.3337, -1.5952, -1.4514,  ..., -1.4992, -1.4971, -1.5148],\n",
       "         [-1.7092, -1.7263, -1.4375,  ..., -1.8299, -1.4984, -1.4911],\n",
       "         ...,\n",
       "         [-1.4072, -1.6641, -1.7351,  ..., -1.6699, -1.8084, -1.4696],\n",
       "         [-1.5174, -1.7515, -1.5336,  ..., -1.4461, -1.6789, -1.0587],\n",
       "         [-1.7994, -1.3123, -1.6555,  ..., -1.7759, -1.8222, -1.4347]],\n",
       "\n",
       "        [[-1.6476, -1.5991, -1.6669,  ..., -1.7333, -1.7224, -1.6762],\n",
       "         [-1.3739, -1.7206, -1.5738,  ..., -1.5877, -1.4844, -1.4666],\n",
       "         [-1.7550, -1.8126, -1.4560,  ..., -1.1913, -1.7262, -1.5442],\n",
       "         ...,\n",
       "         [-1.5775, -1.7211, -1.7374,  ..., -1.6274, -1.6388, -1.7676],\n",
       "         [-1.2962, -1.6645, -1.6026,  ..., -1.6961, -1.5600, -1.4352],\n",
       "         [-1.6964, -1.5579, -1.8554,  ..., -1.6517, -1.6468, -1.8127]]],\n",
       "       device='mps:0', grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timefusion import TimeFusion\n",
    "import torch\n",
    "\n",
    "context = torch.ones([32,100,30,6], dtype=torch.float, device=torch.device(\"mps\"))\n",
    "queries = torch.ones([32,100,30,6], dtype=torch.float, device=torch.device(\"mps\"))\n",
    "\n",
    "k0 = TimeFusion(\n",
    "    6,\n",
    "    [1],\n",
    "    [2],\n",
    "    d_model=16,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    nhead=4,\n",
    "    device=torch.device(\"mps\")\n",
    ")\n",
    "\n",
    "k0(context,queries)\n",
    "\n",
    "#print(\"Number of trainable parameters:\",sum(p.numel() for p in k0.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in k0.parameters():\n",
    "    print(p.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TimeFusion.forward() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k0(out)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: TimeFusion.forward() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "k0(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timefusion import TimeFusion\n",
    "import torch\n",
    "\n",
    "out = torch.ones([32,50,100,6], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "out.random_(0,10)\n",
    "\n",
    "all((torch.flatten(out,start_dim=1,end_dim=2).reshape([32,50,100,6]) == out).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all((torch.flatten(out,start_dim=1,end_dim=2)[:,:,0].reshape([32,50,100]) == out[:,:,:,0]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 8., 7., 1., 0.],\n",
       "          [2., 2., 2., 0., 0., 9.],\n",
       "          [9., 3., 1., 5., 4., 0.],\n",
       "          ...,\n",
       "          [8., 9., 7., 9., 6., 4.],\n",
       "          [3., 5., 3., 8., 6., 6.],\n",
       "          [8., 7., 4., 8., 8., 6.]],\n",
       "\n",
       "         [[3., 0., 9., 7., 3., 6.],\n",
       "          [5., 9., 6., 4., 4., 9.],\n",
       "          [6., 3., 3., 0., 2., 3.],\n",
       "          ...,\n",
       "          [2., 6., 0., 9., 6., 0.],\n",
       "          [1., 7., 2., 4., 6., 1.],\n",
       "          [6., 9., 7., 0., 8., 0.]],\n",
       "\n",
       "         [[0., 4., 6., 0., 3., 9.],\n",
       "          [5., 6., 0., 8., 4., 4.],\n",
       "          [9., 5., 4., 1., 3., 7.],\n",
       "          ...,\n",
       "          [1., 9., 9., 1., 8., 8.],\n",
       "          [3., 1., 0., 5., 1., 3.],\n",
       "          [2., 6., 4., 7., 4., 7.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[5., 0., 6., 5., 2., 2.],\n",
       "          [3., 0., 3., 5., 3., 1.],\n",
       "          [9., 6., 1., 1., 9., 3.],\n",
       "          ...,\n",
       "          [8., 5., 4., 9., 1., 5.],\n",
       "          [3., 2., 2., 1., 7., 2.],\n",
       "          [2., 6., 0., 6., 9., 9.]],\n",
       "\n",
       "         [[2., 1., 2., 5., 4., 8.],\n",
       "          [5., 4., 0., 7., 4., 5.],\n",
       "          [5., 1., 4., 1., 6., 0.],\n",
       "          ...,\n",
       "          [3., 2., 4., 8., 8., 3.],\n",
       "          [8., 3., 9., 6., 1., 5.],\n",
       "          [2., 5., 8., 2., 7., 0.]],\n",
       "\n",
       "         [[2., 4., 0., 6., 6., 4.],\n",
       "          [9., 6., 4., 8., 8., 8.],\n",
       "          [5., 0., 9., 3., 4., 0.],\n",
       "          ...,\n",
       "          [1., 6., 3., 3., 4., 8.],\n",
       "          [4., 2., 8., 3., 2., 4.],\n",
       "          [3., 0., 7., 4., 5., 7.]]],\n",
       "\n",
       "\n",
       "        [[[5., 3., 4., 5., 2., 3.],\n",
       "          [1., 3., 2., 2., 8., 3.],\n",
       "          [8., 5., 4., 7., 4., 3.],\n",
       "          ...,\n",
       "          [3., 3., 0., 5., 0., 0.],\n",
       "          [8., 8., 4., 1., 8., 8.],\n",
       "          [3., 2., 1., 3., 9., 8.]],\n",
       "\n",
       "         [[7., 5., 7., 1., 6., 3.],\n",
       "          [6., 6., 9., 2., 6., 6.],\n",
       "          [6., 4., 8., 9., 3., 2.],\n",
       "          ...,\n",
       "          [9., 9., 5., 8., 9., 2.],\n",
       "          [1., 2., 9., 7., 2., 5.],\n",
       "          [2., 5., 5., 8., 0., 0.]],\n",
       "\n",
       "         [[4., 8., 0., 2., 5., 6.],\n",
       "          [8., 3., 0., 3., 9., 0.],\n",
       "          [2., 7., 1., 0., 7., 0.],\n",
       "          ...,\n",
       "          [0., 7., 5., 4., 7., 6.],\n",
       "          [9., 4., 7., 5., 1., 8.],\n",
       "          [2., 5., 0., 5., 3., 6.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3., 2., 6., 4., 1., 2.],\n",
       "          [1., 6., 8., 1., 6., 2.],\n",
       "          [9., 4., 8., 6., 6., 0.],\n",
       "          ...,\n",
       "          [0., 8., 7., 3., 0., 8.],\n",
       "          [8., 4., 5., 4., 7., 1.],\n",
       "          [0., 0., 8., 5., 9., 1.]],\n",
       "\n",
       "         [[6., 0., 9., 2., 7., 5.],\n",
       "          [7., 3., 9., 9., 3., 4.],\n",
       "          [1., 5., 2., 8., 7., 6.],\n",
       "          ...,\n",
       "          [5., 5., 4., 9., 3., 7.],\n",
       "          [1., 5., 9., 8., 6., 2.],\n",
       "          [9., 6., 9., 1., 7., 2.]],\n",
       "\n",
       "         [[3., 5., 1., 4., 2., 5.],\n",
       "          [2., 6., 5., 8., 5., 1.],\n",
       "          [7., 2., 4., 6., 9., 5.],\n",
       "          ...,\n",
       "          [9., 5., 6., 8., 5., 5.],\n",
       "          [0., 9., 3., 1., 7., 0.],\n",
       "          [7., 6., 4., 5., 0., 2.]]],\n",
       "\n",
       "\n",
       "        [[[9., 5., 4., 4., 7., 5.],\n",
       "          [3., 2., 6., 9., 2., 3.],\n",
       "          [3., 1., 2., 4., 0., 4.],\n",
       "          ...,\n",
       "          [7., 7., 3., 2., 4., 2.],\n",
       "          [0., 3., 2., 5., 2., 1.],\n",
       "          [1., 4., 2., 8., 1., 4.]],\n",
       "\n",
       "         [[5., 2., 8., 9., 5., 3.],\n",
       "          [4., 2., 8., 5., 1., 8.],\n",
       "          [5., 9., 5., 3., 8., 4.],\n",
       "          ...,\n",
       "          [0., 5., 5., 9., 1., 4.],\n",
       "          [4., 3., 7., 0., 0., 7.],\n",
       "          [0., 4., 8., 4., 4., 7.]],\n",
       "\n",
       "         [[7., 5., 8., 7., 9., 9.],\n",
       "          [4., 6., 0., 5., 6., 2.],\n",
       "          [5., 0., 8., 5., 9., 9.],\n",
       "          ...,\n",
       "          [8., 6., 6., 7., 4., 9.],\n",
       "          [9., 4., 3., 4., 5., 9.],\n",
       "          [2., 8., 4., 0., 3., 6.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3., 8., 8., 2., 4., 8.],\n",
       "          [2., 9., 1., 5., 8., 8.],\n",
       "          [2., 5., 1., 7., 3., 1.],\n",
       "          ...,\n",
       "          [0., 9., 4., 0., 2., 4.],\n",
       "          [9., 6., 2., 0., 1., 7.],\n",
       "          [0., 5., 7., 1., 3., 2.]],\n",
       "\n",
       "         [[0., 2., 0., 5., 9., 0.],\n",
       "          [3., 5., 7., 0., 7., 1.],\n",
       "          [6., 6., 9., 1., 7., 3.],\n",
       "          ...,\n",
       "          [5., 8., 3., 9., 8., 3.],\n",
       "          [1., 1., 8., 6., 9., 3.],\n",
       "          [8., 1., 5., 3., 1., 4.]],\n",
       "\n",
       "         [[3., 9., 8., 4., 0., 4.],\n",
       "          [2., 0., 7., 2., 3., 1.],\n",
       "          [8., 1., 3., 5., 1., 2.],\n",
       "          ...,\n",
       "          [9., 1., 9., 1., 8., 4.],\n",
       "          [6., 7., 1., 0., 6., 1.],\n",
       "          [9., 1., 1., 6., 7., 7.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[5., 5., 4., 3., 1., 8.],\n",
       "          [5., 0., 6., 6., 7., 8.],\n",
       "          [7., 7., 4., 4., 1., 7.],\n",
       "          ...,\n",
       "          [4., 6., 5., 6., 7., 6.],\n",
       "          [9., 6., 4., 2., 9., 7.],\n",
       "          [6., 5., 9., 0., 8., 1.]],\n",
       "\n",
       "         [[4., 0., 3., 7., 4., 5.],\n",
       "          [4., 3., 1., 4., 6., 8.],\n",
       "          [7., 3., 7., 4., 1., 5.],\n",
       "          ...,\n",
       "          [6., 6., 7., 2., 0., 1.],\n",
       "          [5., 5., 4., 8., 1., 3.],\n",
       "          [9., 9., 1., 1., 7., 7.]],\n",
       "\n",
       "         [[0., 7., 1., 7., 7., 9.],\n",
       "          [4., 6., 1., 0., 4., 3.],\n",
       "          [6., 4., 9., 0., 9., 4.],\n",
       "          ...,\n",
       "          [4., 8., 4., 7., 3., 2.],\n",
       "          [5., 5., 2., 6., 1., 2.],\n",
       "          [3., 8., 4., 7., 7., 9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8., 8., 5., 7., 4., 4.],\n",
       "          [6., 4., 4., 6., 3., 5.],\n",
       "          [8., 7., 4., 1., 1., 2.],\n",
       "          ...,\n",
       "          [9., 0., 0., 4., 5., 3.],\n",
       "          [9., 9., 1., 4., 6., 0.],\n",
       "          [3., 1., 7., 5., 0., 9.]],\n",
       "\n",
       "         [[5., 8., 1., 2., 4., 0.],\n",
       "          [4., 4., 9., 1., 2., 8.],\n",
       "          [6., 3., 5., 5., 8., 3.],\n",
       "          ...,\n",
       "          [0., 6., 7., 9., 5., 1.],\n",
       "          [9., 0., 4., 1., 4., 9.],\n",
       "          [7., 1., 4., 5., 5., 2.]],\n",
       "\n",
       "         [[5., 2., 9., 1., 2., 3.],\n",
       "          [7., 1., 7., 0., 4., 4.],\n",
       "          [4., 0., 9., 2., 4., 4.],\n",
       "          ...,\n",
       "          [6., 4., 0., 9., 8., 1.],\n",
       "          [1., 0., 0., 8., 9., 7.],\n",
       "          [3., 3., 0., 5., 2., 7.]]],\n",
       "\n",
       "\n",
       "        [[[6., 2., 1., 7., 8., 2.],\n",
       "          [3., 6., 2., 5., 3., 2.],\n",
       "          [1., 0., 7., 9., 8., 8.],\n",
       "          ...,\n",
       "          [7., 0., 1., 9., 0., 6.],\n",
       "          [3., 4., 0., 2., 0., 0.],\n",
       "          [9., 1., 9., 0., 2., 8.]],\n",
       "\n",
       "         [[2., 7., 7., 7., 3., 2.],\n",
       "          [2., 6., 3., 4., 6., 2.],\n",
       "          [4., 4., 7., 1., 0., 8.],\n",
       "          ...,\n",
       "          [3., 9., 2., 1., 7., 7.],\n",
       "          [2., 8., 8., 0., 5., 7.],\n",
       "          [1., 9., 3., 2., 4., 5.]],\n",
       "\n",
       "         [[1., 7., 9., 8., 5., 9.],\n",
       "          [5., 5., 2., 6., 5., 6.],\n",
       "          [9., 0., 4., 2., 6., 1.],\n",
       "          ...,\n",
       "          [2., 9., 7., 3., 5., 4.],\n",
       "          [2., 8., 6., 8., 5., 1.],\n",
       "          [1., 9., 7., 8., 9., 1.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1., 7., 1., 4., 9., 3.],\n",
       "          [1., 8., 5., 9., 0., 7.],\n",
       "          [7., 7., 3., 2., 3., 0.],\n",
       "          ...,\n",
       "          [9., 1., 0., 2., 8., 7.],\n",
       "          [1., 5., 3., 0., 4., 4.],\n",
       "          [5., 5., 6., 0., 1., 7.]],\n",
       "\n",
       "         [[1., 9., 7., 6., 9., 5.],\n",
       "          [4., 3., 9., 4., 5., 4.],\n",
       "          [8., 4., 2., 4., 6., 6.],\n",
       "          ...,\n",
       "          [6., 9., 4., 5., 7., 3.],\n",
       "          [2., 0., 9., 3., 9., 7.],\n",
       "          [2., 9., 9., 0., 4., 2.]],\n",
       "\n",
       "         [[9., 0., 6., 3., 7., 5.],\n",
       "          [6., 5., 3., 9., 2., 8.],\n",
       "          [3., 8., 4., 4., 9., 2.],\n",
       "          ...,\n",
       "          [3., 5., 8., 1., 0., 6.],\n",
       "          [6., 4., 4., 7., 2., 1.],\n",
       "          [8., 6., 8., 9., 6., 0.]]],\n",
       "\n",
       "\n",
       "        [[[5., 6., 3., 5., 2., 0.],\n",
       "          [8., 3., 6., 5., 7., 6.],\n",
       "          [6., 8., 9., 9., 9., 2.],\n",
       "          ...,\n",
       "          [6., 8., 6., 5., 0., 7.],\n",
       "          [3., 3., 0., 9., 0., 4.],\n",
       "          [6., 6., 1., 5., 1., 7.]],\n",
       "\n",
       "         [[6., 4., 7., 5., 8., 6.],\n",
       "          [3., 9., 7., 0., 2., 9.],\n",
       "          [4., 7., 0., 2., 5., 2.],\n",
       "          ...,\n",
       "          [7., 4., 7., 3., 1., 3.],\n",
       "          [1., 3., 6., 2., 0., 7.],\n",
       "          [7., 8., 3., 8., 0., 4.]],\n",
       "\n",
       "         [[0., 1., 6., 1., 0., 0.],\n",
       "          [1., 4., 4., 8., 8., 5.],\n",
       "          [4., 1., 9., 6., 2., 2.],\n",
       "          ...,\n",
       "          [3., 1., 7., 9., 1., 1.],\n",
       "          [0., 9., 4., 7., 2., 3.],\n",
       "          [0., 3., 5., 4., 0., 4.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[6., 4., 8., 3., 8., 1.],\n",
       "          [8., 6., 9., 8., 8., 5.],\n",
       "          [4., 2., 5., 3., 0., 8.],\n",
       "          ...,\n",
       "          [6., 6., 6., 6., 2., 0.],\n",
       "          [4., 4., 8., 7., 2., 2.],\n",
       "          [5., 1., 8., 4., 2., 1.]],\n",
       "\n",
       "         [[8., 2., 3., 7., 9., 3.],\n",
       "          [6., 4., 9., 8., 9., 7.],\n",
       "          [9., 1., 4., 5., 2., 0.],\n",
       "          ...,\n",
       "          [7., 5., 1., 2., 5., 4.],\n",
       "          [3., 7., 5., 5., 6., 1.],\n",
       "          [3., 9., 0., 0., 7., 9.]],\n",
       "\n",
       "         [[1., 3., 7., 8., 2., 1.],\n",
       "          [8., 4., 8., 0., 1., 6.],\n",
       "          [8., 5., 4., 2., 7., 1.],\n",
       "          ...,\n",
       "          [9., 5., 3., 4., 7., 6.],\n",
       "          [5., 2., 4., 0., 6., 4.],\n",
       "          [8., 0., 6., 4., 7., 6.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76341f76697d75e3f89ed083c40b93a39f3367d9447b77c350e7d9ce486d7bff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

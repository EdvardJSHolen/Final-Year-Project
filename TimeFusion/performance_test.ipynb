{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601200000.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t2.timestamp()*1000) % (t3.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "604800000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t3.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27976190476190477"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "t2 = datetime(year=2000,month=10,day=7)\n",
    "t3 = timedelta(weeks=1)\n",
    "\n",
    "((t2.timestamp()*1000) % (t3.total_seconds()*1000))/(t3.total_seconds()*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timedelta(milliseconds=1).total_seconds()*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([True,True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.ones([2,5,4,6], dtype=torch.float64, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape[:-1] + tuple([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len({1,2,3,5,6,6,7,89,0} - {3,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,:,list({1,0})].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 6, 7, 89]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list({1,2,3,5,6,6,7,89,0} - {3,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:,:,:1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 1., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00, -2.4493e-16,\n",
       "        -2.4493e-16,  1.0000e+00,  1.0000e+00,  6.2831e-03,  6.2831e-03,\n",
       "         9.9998e-01,  9.9998e-01,  1.0472e-04,  1.0472e-04,  1.0000e+00,\n",
       "         1.0000e+00,  7.2722e-08,  7.2722e-08,  1.0000e+00,  1.0000e+00,\n",
       "         1.0389e-08,  1.0389e-08,  1.0000e+00,  1.0000e+00,  2.4241e-09,\n",
       "         2.4241e-09,  1.0000e+00,  1.0000e+00,  1.9924e-10,  1.9924e-10,\n",
       "         1.0000e+00,  1.0000e+00,  1.9924e-11,  1.9924e-11,  1.0000e+00,\n",
       "         1.0000e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timefusion import PositionalEncoding\n",
    "import torch\n",
    "\n",
    "out = torch.ones([2,5,4,6], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "k = PositionalEncoding(6,[],[2,5])\n",
    "\n",
    "k(out)[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones([\u001b[39m32\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m6\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m k0 \u001b[39m=\u001b[39m PositionalEncoding(\u001b[39m6\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m,[\u001b[39m2\u001b[39;49m],[\u001b[39m4\u001b[39;49m],num_sines\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m k1 \u001b[39m=\u001b[39m Embedding(k0\u001b[39m.\u001b[39mencoding_dim,\u001b[39m3\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m out \u001b[39m=\u001b[39m k0(out)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/timefusion.py:112\u001b[0m, in \u001b[0;36mPositionalEncoding.__init__\u001b[0;34m(self, datapoint_dim, indices, timestamps, device, num_sines, time_per)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# Assertions to ensure correct usage\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39massert\u001b[39;00m num_sines \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnum_sines\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be an even number\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39;49m(\u001b[39m0\u001b[39;49m \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m idx \u001b[39m<\u001b[39;49m datapoint_dim \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m indices), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindices\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m datapoint_dim \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m timestamps), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimestamps\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Init nn.Module base class\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/timefusion.py:112\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m# Assertions to ensure correct usage\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39massert\u001b[39;00m num_sines \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnum_sines\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be an even number\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 112\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m datapoint_dim \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindices\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m idx \u001b[39m<\u001b[39m datapoint_dim \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m timestamps), \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimestamps\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are out of range\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Init nn.Module base class\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "from timefusion import Embedding, PositionalEncoding\n",
    "import torch\n",
    "\n",
    "out = torch.ones([32,100,100,6], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "k0 = PositionalEncoding(6,\"cpu\",[2],[4],num_sines=20)\n",
    "k1 = Embedding(k0.encoding_dim,3,\"cpu\")\n",
    "\n",
    "out = k0(out)\n",
    "out = k1(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in k0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3611,  0.0547, -0.2151,  ...,  0.0236, -0.0755,  0.0619],\n",
       "         [-0.0938,  0.0656,  0.3135,  ...,  0.0928,  0.5036,  0.1467],\n",
       "         [ 0.3115,  0.0880, -0.0383,  ..., -0.1538,  0.2584, -0.3283],\n",
       "         ...,\n",
       "         [ 0.0280,  0.0997, -0.1567,  ...,  0.1825, -0.0126,  0.0458],\n",
       "         [ 0.1831, -0.0470, -0.1689,  ...,  0.0848, -0.0131,  0.1431],\n",
       "         [-0.0108, -0.2455,  0.1312,  ...,  0.1036, -0.1174,  0.2445]],\n",
       "\n",
       "        [[ 0.1422,  0.4056,  0.1905,  ...,  0.0233,  0.0817,  0.0444],\n",
       "         [ 0.0832, -0.2339,  0.0284,  ..., -0.0694, -0.0855,  0.4663],\n",
       "         [ 0.0714,  0.3465, -0.0388,  ...,  0.3035, -0.2639,  0.1506],\n",
       "         ...,\n",
       "         [ 0.1812,  0.2446, -0.3270,  ...,  0.1910,  0.0325,  0.1923],\n",
       "         [ 0.2105,  0.2900, -0.5765,  ..., -0.0193,  0.4274, -0.0617],\n",
       "         [ 0.4102,  0.2106, -0.0867,  ...,  0.1087, -0.0036, -0.0530]],\n",
       "\n",
       "        [[ 0.2121, -0.0489,  0.0498,  ..., -0.0152,  0.3661, -0.3755],\n",
       "         [ 0.1209,  0.1677, -0.1360,  ...,  0.1361,  0.0113, -0.0146],\n",
       "         [ 0.2530,  0.0538, -0.1171,  ...,  0.1436, -0.1718, -0.0240],\n",
       "         ...,\n",
       "         [ 0.1446,  0.0503,  0.1905,  ...,  0.1435,  0.7269, -0.1026],\n",
       "         [-0.1983, -0.1943, -0.1537,  ...,  0.0985, -0.0646,  0.2126],\n",
       "         [ 0.0510, -0.0326, -0.0113,  ..., -0.0249,  0.0638,  0.6752]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1503,  0.3122, -0.1040,  ...,  0.0802, -0.0851,  0.1630],\n",
       "         [ 0.2229, -0.3544, -0.0255,  ...,  0.0322,  0.0805,  0.0918],\n",
       "         [ 0.0761,  0.0298,  0.0452,  ...,  0.3056,  0.0756,  0.3529],\n",
       "         ...,\n",
       "         [ 0.4544,  0.1931, -0.0471,  ...,  0.1794,  0.0662, -0.1701],\n",
       "         [-0.5315,  0.1764,  0.1035,  ...,  0.2868, -0.0774,  0.2350],\n",
       "         [ 0.2368, -0.0820, -0.0294,  ...,  0.2539,  0.1715,  0.3053]],\n",
       "\n",
       "        [[-0.0434, -0.1014,  0.1622,  ...,  0.3649, -0.1106,  0.2189],\n",
       "         [ 0.2108,  0.2709,  0.2401,  ...,  0.0943,  0.1074,  0.1094],\n",
       "         [-0.1711,  0.3460,  0.0135,  ..., -0.0577,  0.1163, -0.1760],\n",
       "         ...,\n",
       "         [-0.0720, -0.6107, -0.2548,  ..., -0.0197,  0.0426,  0.1847],\n",
       "         [-0.0534, -0.0421,  0.0576,  ...,  0.2444, -0.1688, -0.3064],\n",
       "         [ 0.2505,  0.2444,  0.2677,  ..., -0.1518,  0.1778,  0.2338]],\n",
       "\n",
       "        [[-0.1796,  0.1885,  0.2304,  ...,  0.3159, -0.0496, -0.1613],\n",
       "         [ 0.1146,  0.1845, -0.1384,  ...,  0.6019, -0.2389,  0.2750],\n",
       "         [-0.1786, -0.1565,  0.1583,  ...,  0.2093,  0.3454,  0.0515],\n",
       "         ...,\n",
       "         [ 0.3079, -0.0897,  0.3832,  ...,  0.0302,  0.0788, -0.0294],\n",
       "         [ 0.4333,  0.2451, -0.0624,  ...,  0.2327,  0.2974,  0.2454],\n",
       "         [ 0.0952,  0.1066,  0.1969,  ...,  0.2218,  0.3372,  0.1239]]],\n",
       "       grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timefusion import TimeFusion\n",
    "import torch\n",
    "\n",
    "context = torch.ones([64,25,30,12], dtype=torch.float, device=torch.device(\"mps\"))\n",
    "queries = torch.ones([64,25,30,12], dtype=torch.float, device=torch.device(\"mps\"))\n",
    "\n",
    "k0 = TimeFusion(\n",
    "    6,\n",
    "    [1],\n",
    "    [2],\n",
    "    d_model=64,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=3,\n",
    "    nhead=4,\n",
    "    device=torch.device(\"mps\")\n",
    ")\n",
    "\n",
    "\n",
    "k0(context,queries)\n",
    "\n",
    "#print(\"Number of trainable parameters:\",sum(p.numel() for p in k0.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edvard\n",
      "\n",
      " hi \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "print(\"edvard\")\n",
    "print()\n",
    "for x in [\"hello\",\"hi\"]:\n",
    "    time.sleep(1)\n",
    "    #print(\"\\u007F\"*128,end=\"\")\n",
    "    print(\"\\u007F\"*512,\"\\r\",x, end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tttttttttt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"t\"*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in k0.parameters():\n",
    "    print(p.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TimeFusion.forward() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k0(out)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: TimeFusion.forward() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "k0(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from timefusion import TimeFusion\n",
    "import torch\n",
    "\n",
    "out = torch.ones([32,50,100,6], dtype=torch.float, device=\"cpu\")\n",
    "\n",
    "out.random_(0,10)\n",
    "\n",
    "all((torch.flatten(out,start_dim=1,end_dim=2).reshape([32,50,100,6]) == out).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all((torch.flatten(out,start_dim=1,end_dim=2)[:,:,0].reshape([32,50,100]) == out[:,:,:,0]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 8., 7., 1., 0.],\n",
       "          [2., 2., 2., 0., 0., 9.],\n",
       "          [9., 3., 1., 5., 4., 0.],\n",
       "          ...,\n",
       "          [8., 9., 7., 9., 6., 4.],\n",
       "          [3., 5., 3., 8., 6., 6.],\n",
       "          [8., 7., 4., 8., 8., 6.]],\n",
       "\n",
       "         [[3., 0., 9., 7., 3., 6.],\n",
       "          [5., 9., 6., 4., 4., 9.],\n",
       "          [6., 3., 3., 0., 2., 3.],\n",
       "          ...,\n",
       "          [2., 6., 0., 9., 6., 0.],\n",
       "          [1., 7., 2., 4., 6., 1.],\n",
       "          [6., 9., 7., 0., 8., 0.]],\n",
       "\n",
       "         [[0., 4., 6., 0., 3., 9.],\n",
       "          [5., 6., 0., 8., 4., 4.],\n",
       "          [9., 5., 4., 1., 3., 7.],\n",
       "          ...,\n",
       "          [1., 9., 9., 1., 8., 8.],\n",
       "          [3., 1., 0., 5., 1., 3.],\n",
       "          [2., 6., 4., 7., 4., 7.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[5., 0., 6., 5., 2., 2.],\n",
       "          [3., 0., 3., 5., 3., 1.],\n",
       "          [9., 6., 1., 1., 9., 3.],\n",
       "          ...,\n",
       "          [8., 5., 4., 9., 1., 5.],\n",
       "          [3., 2., 2., 1., 7., 2.],\n",
       "          [2., 6., 0., 6., 9., 9.]],\n",
       "\n",
       "         [[2., 1., 2., 5., 4., 8.],\n",
       "          [5., 4., 0., 7., 4., 5.],\n",
       "          [5., 1., 4., 1., 6., 0.],\n",
       "          ...,\n",
       "          [3., 2., 4., 8., 8., 3.],\n",
       "          [8., 3., 9., 6., 1., 5.],\n",
       "          [2., 5., 8., 2., 7., 0.]],\n",
       "\n",
       "         [[2., 4., 0., 6., 6., 4.],\n",
       "          [9., 6., 4., 8., 8., 8.],\n",
       "          [5., 0., 9., 3., 4., 0.],\n",
       "          ...,\n",
       "          [1., 6., 3., 3., 4., 8.],\n",
       "          [4., 2., 8., 3., 2., 4.],\n",
       "          [3., 0., 7., 4., 5., 7.]]],\n",
       "\n",
       "\n",
       "        [[[5., 3., 4., 5., 2., 3.],\n",
       "          [1., 3., 2., 2., 8., 3.],\n",
       "          [8., 5., 4., 7., 4., 3.],\n",
       "          ...,\n",
       "          [3., 3., 0., 5., 0., 0.],\n",
       "          [8., 8., 4., 1., 8., 8.],\n",
       "          [3., 2., 1., 3., 9., 8.]],\n",
       "\n",
       "         [[7., 5., 7., 1., 6., 3.],\n",
       "          [6., 6., 9., 2., 6., 6.],\n",
       "          [6., 4., 8., 9., 3., 2.],\n",
       "          ...,\n",
       "          [9., 9., 5., 8., 9., 2.],\n",
       "          [1., 2., 9., 7., 2., 5.],\n",
       "          [2., 5., 5., 8., 0., 0.]],\n",
       "\n",
       "         [[4., 8., 0., 2., 5., 6.],\n",
       "          [8., 3., 0., 3., 9., 0.],\n",
       "          [2., 7., 1., 0., 7., 0.],\n",
       "          ...,\n",
       "          [0., 7., 5., 4., 7., 6.],\n",
       "          [9., 4., 7., 5., 1., 8.],\n",
       "          [2., 5., 0., 5., 3., 6.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3., 2., 6., 4., 1., 2.],\n",
       "          [1., 6., 8., 1., 6., 2.],\n",
       "          [9., 4., 8., 6., 6., 0.],\n",
       "          ...,\n",
       "          [0., 8., 7., 3., 0., 8.],\n",
       "          [8., 4., 5., 4., 7., 1.],\n",
       "          [0., 0., 8., 5., 9., 1.]],\n",
       "\n",
       "         [[6., 0., 9., 2., 7., 5.],\n",
       "          [7., 3., 9., 9., 3., 4.],\n",
       "          [1., 5., 2., 8., 7., 6.],\n",
       "          ...,\n",
       "          [5., 5., 4., 9., 3., 7.],\n",
       "          [1., 5., 9., 8., 6., 2.],\n",
       "          [9., 6., 9., 1., 7., 2.]],\n",
       "\n",
       "         [[3., 5., 1., 4., 2., 5.],\n",
       "          [2., 6., 5., 8., 5., 1.],\n",
       "          [7., 2., 4., 6., 9., 5.],\n",
       "          ...,\n",
       "          [9., 5., 6., 8., 5., 5.],\n",
       "          [0., 9., 3., 1., 7., 0.],\n",
       "          [7., 6., 4., 5., 0., 2.]]],\n",
       "\n",
       "\n",
       "        [[[9., 5., 4., 4., 7., 5.],\n",
       "          [3., 2., 6., 9., 2., 3.],\n",
       "          [3., 1., 2., 4., 0., 4.],\n",
       "          ...,\n",
       "          [7., 7., 3., 2., 4., 2.],\n",
       "          [0., 3., 2., 5., 2., 1.],\n",
       "          [1., 4., 2., 8., 1., 4.]],\n",
       "\n",
       "         [[5., 2., 8., 9., 5., 3.],\n",
       "          [4., 2., 8., 5., 1., 8.],\n",
       "          [5., 9., 5., 3., 8., 4.],\n",
       "          ...,\n",
       "          [0., 5., 5., 9., 1., 4.],\n",
       "          [4., 3., 7., 0., 0., 7.],\n",
       "          [0., 4., 8., 4., 4., 7.]],\n",
       "\n",
       "         [[7., 5., 8., 7., 9., 9.],\n",
       "          [4., 6., 0., 5., 6., 2.],\n",
       "          [5., 0., 8., 5., 9., 9.],\n",
       "          ...,\n",
       "          [8., 6., 6., 7., 4., 9.],\n",
       "          [9., 4., 3., 4., 5., 9.],\n",
       "          [2., 8., 4., 0., 3., 6.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[3., 8., 8., 2., 4., 8.],\n",
       "          [2., 9., 1., 5., 8., 8.],\n",
       "          [2., 5., 1., 7., 3., 1.],\n",
       "          ...,\n",
       "          [0., 9., 4., 0., 2., 4.],\n",
       "          [9., 6., 2., 0., 1., 7.],\n",
       "          [0., 5., 7., 1., 3., 2.]],\n",
       "\n",
       "         [[0., 2., 0., 5., 9., 0.],\n",
       "          [3., 5., 7., 0., 7., 1.],\n",
       "          [6., 6., 9., 1., 7., 3.],\n",
       "          ...,\n",
       "          [5., 8., 3., 9., 8., 3.],\n",
       "          [1., 1., 8., 6., 9., 3.],\n",
       "          [8., 1., 5., 3., 1., 4.]],\n",
       "\n",
       "         [[3., 9., 8., 4., 0., 4.],\n",
       "          [2., 0., 7., 2., 3., 1.],\n",
       "          [8., 1., 3., 5., 1., 2.],\n",
       "          ...,\n",
       "          [9., 1., 9., 1., 8., 4.],\n",
       "          [6., 7., 1., 0., 6., 1.],\n",
       "          [9., 1., 1., 6., 7., 7.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[5., 5., 4., 3., 1., 8.],\n",
       "          [5., 0., 6., 6., 7., 8.],\n",
       "          [7., 7., 4., 4., 1., 7.],\n",
       "          ...,\n",
       "          [4., 6., 5., 6., 7., 6.],\n",
       "          [9., 6., 4., 2., 9., 7.],\n",
       "          [6., 5., 9., 0., 8., 1.]],\n",
       "\n",
       "         [[4., 0., 3., 7., 4., 5.],\n",
       "          [4., 3., 1., 4., 6., 8.],\n",
       "          [7., 3., 7., 4., 1., 5.],\n",
       "          ...,\n",
       "          [6., 6., 7., 2., 0., 1.],\n",
       "          [5., 5., 4., 8., 1., 3.],\n",
       "          [9., 9., 1., 1., 7., 7.]],\n",
       "\n",
       "         [[0., 7., 1., 7., 7., 9.],\n",
       "          [4., 6., 1., 0., 4., 3.],\n",
       "          [6., 4., 9., 0., 9., 4.],\n",
       "          ...,\n",
       "          [4., 8., 4., 7., 3., 2.],\n",
       "          [5., 5., 2., 6., 1., 2.],\n",
       "          [3., 8., 4., 7., 7., 9.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[8., 8., 5., 7., 4., 4.],\n",
       "          [6., 4., 4., 6., 3., 5.],\n",
       "          [8., 7., 4., 1., 1., 2.],\n",
       "          ...,\n",
       "          [9., 0., 0., 4., 5., 3.],\n",
       "          [9., 9., 1., 4., 6., 0.],\n",
       "          [3., 1., 7., 5., 0., 9.]],\n",
       "\n",
       "         [[5., 8., 1., 2., 4., 0.],\n",
       "          [4., 4., 9., 1., 2., 8.],\n",
       "          [6., 3., 5., 5., 8., 3.],\n",
       "          ...,\n",
       "          [0., 6., 7., 9., 5., 1.],\n",
       "          [9., 0., 4., 1., 4., 9.],\n",
       "          [7., 1., 4., 5., 5., 2.]],\n",
       "\n",
       "         [[5., 2., 9., 1., 2., 3.],\n",
       "          [7., 1., 7., 0., 4., 4.],\n",
       "          [4., 0., 9., 2., 4., 4.],\n",
       "          ...,\n",
       "          [6., 4., 0., 9., 8., 1.],\n",
       "          [1., 0., 0., 8., 9., 7.],\n",
       "          [3., 3., 0., 5., 2., 7.]]],\n",
       "\n",
       "\n",
       "        [[[6., 2., 1., 7., 8., 2.],\n",
       "          [3., 6., 2., 5., 3., 2.],\n",
       "          [1., 0., 7., 9., 8., 8.],\n",
       "          ...,\n",
       "          [7., 0., 1., 9., 0., 6.],\n",
       "          [3., 4., 0., 2., 0., 0.],\n",
       "          [9., 1., 9., 0., 2., 8.]],\n",
       "\n",
       "         [[2., 7., 7., 7., 3., 2.],\n",
       "          [2., 6., 3., 4., 6., 2.],\n",
       "          [4., 4., 7., 1., 0., 8.],\n",
       "          ...,\n",
       "          [3., 9., 2., 1., 7., 7.],\n",
       "          [2., 8., 8., 0., 5., 7.],\n",
       "          [1., 9., 3., 2., 4., 5.]],\n",
       "\n",
       "         [[1., 7., 9., 8., 5., 9.],\n",
       "          [5., 5., 2., 6., 5., 6.],\n",
       "          [9., 0., 4., 2., 6., 1.],\n",
       "          ...,\n",
       "          [2., 9., 7., 3., 5., 4.],\n",
       "          [2., 8., 6., 8., 5., 1.],\n",
       "          [1., 9., 7., 8., 9., 1.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1., 7., 1., 4., 9., 3.],\n",
       "          [1., 8., 5., 9., 0., 7.],\n",
       "          [7., 7., 3., 2., 3., 0.],\n",
       "          ...,\n",
       "          [9., 1., 0., 2., 8., 7.],\n",
       "          [1., 5., 3., 0., 4., 4.],\n",
       "          [5., 5., 6., 0., 1., 7.]],\n",
       "\n",
       "         [[1., 9., 7., 6., 9., 5.],\n",
       "          [4., 3., 9., 4., 5., 4.],\n",
       "          [8., 4., 2., 4., 6., 6.],\n",
       "          ...,\n",
       "          [6., 9., 4., 5., 7., 3.],\n",
       "          [2., 0., 9., 3., 9., 7.],\n",
       "          [2., 9., 9., 0., 4., 2.]],\n",
       "\n",
       "         [[9., 0., 6., 3., 7., 5.],\n",
       "          [6., 5., 3., 9., 2., 8.],\n",
       "          [3., 8., 4., 4., 9., 2.],\n",
       "          ...,\n",
       "          [3., 5., 8., 1., 0., 6.],\n",
       "          [6., 4., 4., 7., 2., 1.],\n",
       "          [8., 6., 8., 9., 6., 0.]]],\n",
       "\n",
       "\n",
       "        [[[5., 6., 3., 5., 2., 0.],\n",
       "          [8., 3., 6., 5., 7., 6.],\n",
       "          [6., 8., 9., 9., 9., 2.],\n",
       "          ...,\n",
       "          [6., 8., 6., 5., 0., 7.],\n",
       "          [3., 3., 0., 9., 0., 4.],\n",
       "          [6., 6., 1., 5., 1., 7.]],\n",
       "\n",
       "         [[6., 4., 7., 5., 8., 6.],\n",
       "          [3., 9., 7., 0., 2., 9.],\n",
       "          [4., 7., 0., 2., 5., 2.],\n",
       "          ...,\n",
       "          [7., 4., 7., 3., 1., 3.],\n",
       "          [1., 3., 6., 2., 0., 7.],\n",
       "          [7., 8., 3., 8., 0., 4.]],\n",
       "\n",
       "         [[0., 1., 6., 1., 0., 0.],\n",
       "          [1., 4., 4., 8., 8., 5.],\n",
       "          [4., 1., 9., 6., 2., 2.],\n",
       "          ...,\n",
       "          [3., 1., 7., 9., 1., 1.],\n",
       "          [0., 9., 4., 7., 2., 3.],\n",
       "          [0., 3., 5., 4., 0., 4.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[6., 4., 8., 3., 8., 1.],\n",
       "          [8., 6., 9., 8., 8., 5.],\n",
       "          [4., 2., 5., 3., 0., 8.],\n",
       "          ...,\n",
       "          [6., 6., 6., 6., 2., 0.],\n",
       "          [4., 4., 8., 7., 2., 2.],\n",
       "          [5., 1., 8., 4., 2., 1.]],\n",
       "\n",
       "         [[8., 2., 3., 7., 9., 3.],\n",
       "          [6., 4., 9., 8., 9., 7.],\n",
       "          [9., 1., 4., 5., 2., 0.],\n",
       "          ...,\n",
       "          [7., 5., 1., 2., 5., 4.],\n",
       "          [3., 7., 5., 5., 6., 1.],\n",
       "          [3., 9., 0., 0., 7., 9.]],\n",
       "\n",
       "         [[1., 3., 7., 8., 2., 1.],\n",
       "          [8., 4., 8., 0., 1., 6.],\n",
       "          [8., 5., 4., 2., 7., 1.],\n",
       "          ...,\n",
       "          [9., 5., 3., 4., 7., 6.],\n",
       "          [5., 2., 4., 0., 6., 4.],\n",
       "          [8., 0., 6., 4., 7., 6.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76341f76697d75e3f89ed083c40b93a39f3367d9447b77c350e7d9ce486d7bff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

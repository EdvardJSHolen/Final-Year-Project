{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from data import TimeFusionDataset\n",
    "from timefusion import TimeFusion\n",
    "from utils.metrics import variogram_score, crps_sum\n",
    "from utils.modules import EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train_data = pd.read_csv(\"../datasets/electricity/train.csv\").set_index(\"date\")\n",
    "test_data = pd.read_csv(\"../datasets/electricity/test.csv\").set_index(\"date\")\n",
    "train_data = train_data.iloc[:,:20]\n",
    "test_data = test_data.iloc[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "    #device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 30\n",
    "prediction_length = 30\n",
    "\n",
    "# Create each dataset\n",
    "train_dataset = TimeFusionDataset(\n",
    "    data = train_data.iloc[:int(0.9*len(train_data))],\n",
    "    context_length = context_length,\n",
    ")\n",
    "\n",
    "val_dataset = TimeFusionDataset(\n",
    "    data = train_data.iloc[int(0.9*len(train_data)):],\n",
    "    context_length = context_length,\n",
    ")\n",
    "\n",
    "test_dataset = TimeFusionDataset(\n",
    "    data = test_data,\n",
    "    context_length = context_length,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    batch_size = 128,\n",
    "    #pin_memory=True,\n",
    "    #pin_memory_device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    batch_size = 128,\n",
    "    #pin_memory=True,\n",
    "    #pin_memory_device=\"cuda:0\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 30174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edvard/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/timefusion/diffusion.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.bar_alphas = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeFusion(\n",
    "    context_length = context_length,\n",
    "    prediction_length = prediction_length,\n",
    "    input_size =  train_data.shape[1],\n",
    "    num_ts = train_data.shape[1],\n",
    "    scaling = True,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "print(\"Number of trainable parameters:\",sum(p.numel() for p in predictor.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.1154,  0.1309,  0.0534,  ...,  0.0418,  0.0964,  0.1605],\n",
      "        [-0.0036,  0.1596,  0.0764,  ...,  0.0390, -0.1122,  0.0428],\n",
      "        [ 0.1047,  0.0527,  0.0078,  ...,  0.1397, -0.0387, -0.0371],\n",
      "        ...,\n",
      "        [ 0.0781,  0.0883,  0.0052,  ..., -0.1725,  0.1355,  0.0918],\n",
      "        [-0.0036,  0.1650, -0.0304,  ...,  0.0797,  0.1394, -0.1062],\n",
      "        [-0.0126,  0.1217,  0.0478,  ...,  0.1303, -0.0418,  0.1540]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1522, -0.0705, -0.1467, -0.0455, -0.0890, -0.1329,  0.1645, -0.0608,\n",
      "        -0.1595, -0.1289, -0.0116,  0.1547, -0.0442, -0.0624, -0.1697, -0.1186,\n",
      "        -0.0459, -0.0053, -0.1464, -0.1115,  0.0855,  0.1653,  0.0148,  0.0285,\n",
      "         0.0304, -0.1486, -0.0136, -0.0405, -0.0365,  0.1291,  0.1049, -0.0765],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0220, -0.0516, -0.0466,  ...,  0.1607, -0.1657, -0.1509],\n",
      "        [ 0.0816, -0.0965, -0.1427,  ..., -0.0131, -0.1187,  0.0624],\n",
      "        [ 0.0958,  0.0023, -0.1305,  ..., -0.1649, -0.0837,  0.0333],\n",
      "        ...,\n",
      "        [ 0.1235,  0.1043,  0.0628,  ..., -0.1107, -0.1572, -0.1399],\n",
      "        [ 0.0853,  0.1623,  0.1371,  ..., -0.0500,  0.1038, -0.1117],\n",
      "        [ 0.0066, -0.0910,  0.1496,  ..., -0.0417, -0.1543,  0.1722]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0155,  0.1405, -0.0831, -0.0297,  0.1675, -0.1526, -0.1712, -0.1401,\n",
      "        -0.1078,  0.1354,  0.0778, -0.0957, -0.0471, -0.1499, -0.1758,  0.1380,\n",
      "        -0.0915,  0.1020,  0.0556, -0.0946, -0.0694,  0.0546, -0.0111,  0.1200,\n",
      "        -0.0117,  0.0668, -0.1600, -0.0633, -0.0343,  0.0942, -0.0091, -0.1189],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0598,  0.1094, -0.0166,  ..., -0.0670,  0.0018, -0.1516],\n",
      "        [-0.1019, -0.0096, -0.0007,  ...,  0.1143, -0.0470, -0.1210],\n",
      "        [-0.0692, -0.1571, -0.0378,  ...,  0.0272,  0.1491,  0.1228],\n",
      "        ...,\n",
      "        [ 0.0578, -0.1363, -0.0980,  ..., -0.0481,  0.0703, -0.1300],\n",
      "        [ 0.0524, -0.1374,  0.0573,  ..., -0.0940,  0.1417, -0.0680],\n",
      "        [ 0.0734, -0.0282, -0.0909,  ...,  0.1258,  0.0743,  0.0398]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1457,  0.1151,  0.1093,  ..., -0.1195,  0.1191,  0.1080],\n",
      "        [ 0.0525, -0.0928, -0.1157,  ...,  0.0124, -0.0689,  0.0606],\n",
      "        [-0.1169, -0.1061,  0.0675,  ..., -0.1321, -0.1560, -0.1007],\n",
      "        ...,\n",
      "        [-0.0823, -0.0803, -0.0859,  ...,  0.0488,  0.0219, -0.1547],\n",
      "        [ 0.0201, -0.0291, -0.0911,  ..., -0.0802, -0.1397,  0.0094],\n",
      "        [-0.0357, -0.0712,  0.0148,  ..., -0.0441,  0.1438, -0.0389]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0069, -0.0519,  0.0653, -0.0384, -0.0938, -0.1327,  0.1385, -0.1131,\n",
      "         0.1232, -0.0809,  0.0169,  0.1119, -0.1258, -0.0757, -0.1543, -0.0645,\n",
      "        -0.1395, -0.0511,  0.1021,  0.0064, -0.0890, -0.0644, -0.1466, -0.0157,\n",
      "        -0.0237,  0.1277,  0.0021, -0.0501, -0.1536, -0.0749, -0.0383,  0.1199,\n",
      "         0.0320, -0.1179,  0.1081,  0.0064,  0.1290,  0.1213,  0.0151,  0.1202,\n",
      "         0.0952, -0.0364, -0.0745, -0.0935, -0.1459, -0.1138,  0.1361,  0.0434,\n",
      "         0.1072,  0.0016, -0.1384,  0.0667, -0.0144, -0.1418,  0.1418, -0.0557,\n",
      "        -0.1209, -0.0608,  0.0547,  0.1397, -0.0148,  0.0763, -0.0927, -0.1405,\n",
      "         0.0158,  0.1132, -0.1071, -0.1081,  0.1111,  0.0300,  0.0503,  0.0837,\n",
      "        -0.0662, -0.0403,  0.1110,  0.0751,  0.0683,  0.0712, -0.0080,  0.0085,\n",
      "        -0.0007, -0.1075, -0.0765, -0.0958,  0.0148, -0.1422, -0.0952,  0.1458,\n",
      "         0.1331,  0.0617, -0.0542, -0.1059,  0.1186,  0.0196, -0.1158, -0.1195,\n",
      "         0.0322, -0.0621,  0.0760, -0.1437,  0.0260, -0.0538,  0.1277, -0.0951,\n",
      "         0.1091, -0.0063,  0.0369, -0.1404,  0.0969, -0.0756, -0.0034, -0.0188,\n",
      "        -0.0295, -0.0512, -0.0921, -0.0662, -0.0396, -0.0920,  0.0699, -0.0623,\n",
      "         0.0301, -0.1569, -0.1559,  0.0691, -0.1542, -0.0331,  0.1006,  0.1461,\n",
      "        -0.0151, -0.0563, -0.1139, -0.1391, -0.0169, -0.1143,  0.0983,  0.0885,\n",
      "        -0.0749,  0.0475,  0.0246,  0.0424,  0.0375,  0.0579,  0.0310, -0.1049,\n",
      "        -0.0639, -0.1370, -0.1048, -0.0256, -0.1064, -0.0447,  0.0293, -0.1083,\n",
      "        -0.0908,  0.1155, -0.0310, -0.0737, -0.0261, -0.0779,  0.0993, -0.1133],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.1110,  0.1197,  0.0184, -0.1453,  0.0183, -0.0398, -0.0125, -0.0167,\n",
      "         0.0947,  0.0112, -0.0192,  0.0890, -0.0789, -0.0765, -0.0629,  0.1378,\n",
      "        -0.0105,  0.0482, -0.0601,  0.0665,  0.1506,  0.1361,  0.1273,  0.0224,\n",
      "         0.0850, -0.0781,  0.0123, -0.1141, -0.0148,  0.0092,  0.0115, -0.1222,\n",
      "        -0.1136,  0.0157, -0.1368, -0.0408, -0.0483, -0.0933,  0.0935,  0.0680,\n",
      "         0.1306, -0.0577, -0.1338,  0.1035,  0.1352,  0.0981,  0.1178, -0.1421,\n",
      "         0.0468, -0.0610, -0.0039, -0.1391, -0.1436,  0.0753,  0.1186, -0.0553,\n",
      "        -0.0045,  0.1441,  0.0708,  0.1578,  0.0714, -0.0317,  0.0490, -0.0517,\n",
      "         0.1169,  0.1056, -0.1312, -0.0916,  0.1228,  0.0287,  0.1241, -0.0952,\n",
      "         0.0708, -0.0882,  0.1008,  0.1289,  0.0056,  0.0833, -0.0036, -0.0727,\n",
      "        -0.0379,  0.1157, -0.0402,  0.0920,  0.1421,  0.1011,  0.0432, -0.0506,\n",
      "         0.0705, -0.1505, -0.0982,  0.1186, -0.0209, -0.0345, -0.1217, -0.0728,\n",
      "        -0.0730,  0.0737, -0.1228, -0.1576,  0.0811,  0.0275,  0.0461,  0.0144,\n",
      "         0.0662, -0.1322, -0.0314, -0.1169, -0.0685,  0.0219,  0.1334,  0.0432,\n",
      "        -0.0268,  0.0564,  0.0724,  0.0827,  0.0152, -0.0713, -0.0757, -0.0465,\n",
      "         0.0569,  0.1566, -0.1376,  0.0132,  0.1318,  0.0535,  0.1390, -0.1387,\n",
      "         0.0441, -0.0723,  0.0226,  0.0256,  0.1063,  0.0327,  0.1092,  0.0444,\n",
      "        -0.1023, -0.0351, -0.0740,  0.0521,  0.1125, -0.0707,  0.0692, -0.0172,\n",
      "         0.0413,  0.1514,  0.0147,  0.0840,  0.1381,  0.0246, -0.1356,  0.0059,\n",
      "        -0.1277, -0.1386, -0.0018, -0.1486,  0.1306, -0.1047,  0.0729, -0.0834],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0878,  0.1057, -0.0268,  ..., -0.0342,  0.0625,  0.1581],\n",
      "        [ 0.1245,  0.1312,  0.0818,  ...,  0.0606, -0.1261,  0.1344],\n",
      "        [-0.1496,  0.1535, -0.0050,  ..., -0.0192,  0.0634,  0.0094],\n",
      "        ...,\n",
      "        [ 0.1006, -0.0612, -0.0972,  ..., -0.1080, -0.1305, -0.1350],\n",
      "        [-0.1366, -0.0348, -0.0069,  ...,  0.0574,  0.1372,  0.1317],\n",
      "        [ 0.0307, -0.1058,  0.1110,  ..., -0.1255, -0.1544, -0.1296]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0813, -0.0311, -0.1162,  ...,  0.0723, -0.0896, -0.0646],\n",
      "        [-0.0879,  0.1035,  0.1030,  ..., -0.1504,  0.0147,  0.1057],\n",
      "        [ 0.0217, -0.0289, -0.1002,  ...,  0.0604,  0.1380,  0.1382],\n",
      "        ...,\n",
      "        [-0.0604, -0.1275, -0.0937,  ..., -0.1004, -0.1352,  0.0036],\n",
      "        [ 0.1374, -0.0997,  0.1289,  ...,  0.0824, -0.0544,  0.0892],\n",
      "        [ 0.0434,  0.0571, -0.1131,  ..., -0.0662, -0.0984, -0.0519]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0995,  0.0161, -0.0488,  0.1316,  0.1082,  0.0779,  0.0949,  0.1004,\n",
      "         0.0236, -0.0953,  0.0981, -0.1053, -0.0175,  0.1290, -0.1078,  0.1236,\n",
      "        -0.1136,  0.0133, -0.0735,  0.1064, -0.1102, -0.1011, -0.0389, -0.0086,\n",
      "        -0.0237,  0.0486,  0.1160,  0.1526,  0.1132,  0.1338, -0.1455,  0.1485,\n",
      "        -0.0653,  0.1005,  0.1299,  0.0945,  0.0103,  0.1265,  0.1496,  0.1225,\n",
      "        -0.0179,  0.0325, -0.0225,  0.0099,  0.1079,  0.0567,  0.0060,  0.1179,\n",
      "         0.0097,  0.1489, -0.1130,  0.1553,  0.1351,  0.0507,  0.0847,  0.0410,\n",
      "        -0.1334,  0.0215,  0.1344,  0.1506,  0.0748, -0.0886,  0.1498,  0.1572,\n",
      "        -0.0562,  0.1566,  0.1225, -0.0805, -0.0581, -0.0011,  0.0132,  0.0596,\n",
      "         0.1561, -0.0555,  0.1334,  0.1511,  0.0015,  0.0681, -0.1269,  0.0582,\n",
      "         0.0495,  0.0572, -0.0006,  0.0581, -0.0354, -0.0909,  0.1384,  0.0436,\n",
      "        -0.0929, -0.1140, -0.0676, -0.0180, -0.0113, -0.0956, -0.1208, -0.0249,\n",
      "        -0.0146, -0.0447, -0.1245, -0.0416,  0.0856,  0.0040,  0.0909,  0.0411,\n",
      "         0.0100,  0.0795, -0.1202,  0.1362,  0.0354, -0.0388,  0.0151,  0.0215,\n",
      "         0.1193,  0.0082, -0.1167,  0.0629,  0.0440,  0.0476,  0.0487, -0.1161,\n",
      "         0.0741, -0.0697,  0.0165,  0.0698, -0.1285,  0.0620,  0.0459,  0.1364,\n",
      "         0.0660, -0.0457, -0.0267,  0.0085,  0.0774, -0.1105, -0.0953, -0.0510,\n",
      "         0.0879, -0.0251,  0.0543,  0.0863, -0.1576, -0.1420,  0.0731, -0.0835,\n",
      "         0.0797, -0.0398,  0.0293,  0.0555, -0.0611, -0.0852,  0.1530, -0.1102,\n",
      "        -0.0346,  0.0292,  0.1541, -0.1218, -0.0098,  0.1220,  0.0055,  0.1312],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1072,  0.0777,  0.1348,  0.0492, -0.1300, -0.1407, -0.1495, -0.0950,\n",
      "         0.1426, -0.0615, -0.0822,  0.1290, -0.1351,  0.0911, -0.1289,  0.0692,\n",
      "         0.0551,  0.0237,  0.0989, -0.0078, -0.0130,  0.1329, -0.0313, -0.0022,\n",
      "        -0.0639, -0.0446, -0.0616,  0.0095, -0.1328,  0.1266,  0.1334,  0.1198,\n",
      "         0.0583,  0.1160,  0.0855, -0.1117, -0.0306,  0.1564,  0.0341,  0.1519,\n",
      "         0.1182,  0.1124,  0.1252,  0.0160,  0.0687, -0.1517, -0.0170,  0.1381,\n",
      "        -0.0348, -0.1163, -0.1350, -0.0179,  0.0239, -0.0951,  0.0543, -0.1178,\n",
      "         0.0173,  0.0701,  0.0711,  0.0686, -0.0163,  0.0021, -0.0179,  0.1007,\n",
      "         0.0164,  0.1517,  0.0437, -0.1178, -0.0947, -0.0648, -0.1493, -0.1357,\n",
      "        -0.1559, -0.0980,  0.1291,  0.1411, -0.0005, -0.1313,  0.1022,  0.0960,\n",
      "        -0.0699, -0.0125,  0.1036, -0.0872, -0.0059, -0.1396,  0.1377, -0.1302,\n",
      "        -0.1066,  0.1215, -0.0932, -0.0570, -0.1417, -0.0725, -0.0706,  0.1363,\n",
      "        -0.0534, -0.1539,  0.1237,  0.1161, -0.0359,  0.0392,  0.0530,  0.1342,\n",
      "         0.1057,  0.1394,  0.1116,  0.1419, -0.1573,  0.0751, -0.0395,  0.1514,\n",
      "         0.1381,  0.1244, -0.0437, -0.1457,  0.0036,  0.0921, -0.1476,  0.0990,\n",
      "         0.1426, -0.0308,  0.0104, -0.0434, -0.0968, -0.1538,  0.0865,  0.0994,\n",
      "        -0.1416,  0.0721,  0.1364,  0.1304,  0.1532, -0.0589, -0.0261, -0.0161,\n",
      "         0.0753,  0.1102,  0.1130, -0.0161,  0.1259,  0.0577,  0.1227,  0.1100,\n",
      "         0.0318,  0.0822,  0.0325,  0.0931, -0.0307,  0.1270,  0.0799, -0.0391,\n",
      "         0.0224,  0.0357, -0.0726, -0.0452,  0.0898,  0.1169, -0.0359, -0.1044],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0498, -0.1270,  0.0311,  ...,  0.0397, -0.1214, -0.0270],\n",
      "        [ 0.0484, -0.1249,  0.0999,  ...,  0.1111, -0.0979, -0.1213],\n",
      "        [-0.0836,  0.1123,  0.0771,  ..., -0.1109,  0.0653, -0.0573],\n",
      "        ...,\n",
      "        [ 0.0072,  0.1022, -0.0469,  ...,  0.0931, -0.1143,  0.1092],\n",
      "        [-0.0838, -0.0417, -0.1096,  ..., -0.0073, -0.1043,  0.1083],\n",
      "        [ 0.0565, -0.0557,  0.0584,  ..., -0.0625,  0.0406, -0.1254]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0274,  0.0730, -0.1177, -0.0734, -0.0241,  0.0963,  0.0200, -0.0914,\n",
      "        -0.1127,  0.0161,  0.0127,  0.0580, -0.0658,  0.0447, -0.0679,  0.0892,\n",
      "        -0.0779, -0.0829,  0.0403, -0.0515, -0.1237, -0.0086, -0.0443,  0.0235,\n",
      "        -0.0085, -0.0343, -0.0159, -0.0062,  0.0248,  0.0966, -0.0640,  0.0309,\n",
      "         0.1174, -0.0428, -0.0838,  0.0380,  0.0675,  0.0743, -0.0228, -0.0957,\n",
      "         0.1137,  0.0316, -0.0860, -0.0466,  0.0123,  0.1262, -0.0982, -0.0995,\n",
      "         0.0368, -0.0741,  0.0245, -0.0931, -0.0436,  0.0797,  0.0127,  0.0259,\n",
      "         0.0249, -0.0947,  0.0541,  0.1073, -0.0109], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0263, -0.1256,  0.1212,  ..., -0.0140, -0.0131,  0.0563],\n",
      "        [ 0.0044,  0.0513, -0.0864,  ..., -0.1056,  0.0651, -0.1055],\n",
      "        [-0.0455,  0.0979, -0.0153,  ..., -0.0064,  0.0656,  0.0249],\n",
      "        ...,\n",
      "        [-0.0229,  0.0725,  0.0994,  ..., -0.0648,  0.0472, -0.0678],\n",
      "        [ 0.0372,  0.1222,  0.0135,  ..., -0.0234, -0.1177, -0.1007],\n",
      "        [-0.0577,  0.0469, -0.1217,  ..., -0.1126,  0.0503, -0.0329]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0597, -0.1067, -0.0122, -0.1205,  0.0969,  0.0808,  0.1226,  0.0798,\n",
      "         0.0530, -0.0713,  0.0125,  0.1024,  0.0205, -0.0403, -0.1032,  0.1166,\n",
      "        -0.0326, -0.0412,  0.1231, -0.0197], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in predictor.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |==============================|  Batch: 170 / 170, Epoch: 1 / 10, Average Loss: 0.9705\n",
      " |==============================|  Batch: 170 / 170, Epoch: 2 / 10, Average Loss: 0.8388\n",
      " |==============================|  Batch: 170 / 170, Epoch: 3 / 10, Average Loss: 0.7197\n",
      " |==============================|  Batch: 170 / 170, Epoch: 4 / 10, Average Loss: 0.6166\n",
      " |==============================|  Batch: 170 / 170, Epoch: 5 / 10, Average Loss: 0.5289\n",
      " |==============================|  Batch: 170 / 170, Epoch: 6 / 10, Average Loss: 0.4579\n",
      " |==============================|  Batch: 170 / 170, Epoch: 7 / 10, Average Loss: 0.4010\n",
      " |==============================|  Batch: 170 / 170, Epoch: 8 / 10, Average Loss: 0.3533\n",
      " |==============================|  Batch: 170 / 170, Epoch: 9 / 10, Average Loss: 0.3146\n",
      " |==============================|  Batch: 170 / 170, Epoch: 10 / 10, Average Loss: 0.2876\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=predictor.parameters(),lr=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1, end_factor=0.01, total_iters=40)\n",
    "\n",
    "predictor.train_network(\n",
    "    train_loader = train_loader,\n",
    "    epochs=40,\n",
    "    val_loader = val_loader,\n",
    "    val_metrics= {\n",
    "        \"Val MAE\": nn.L1Loss(),\n",
    "    },\n",
    "    optimizer = optimizer,\n",
    "    lr_scheduler= lr_scheduler,\n",
    "    early_stopper=EarlyStopper(patience=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../training_scripts/weights/2023-04-17-23-01-43'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictor\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m../training_scripts/weights/2023-04-17-23-01-43\u001b[39;49m\u001b[39m\"\u001b[39;49m,map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m      3\u001b[0m predictor\u001b[39m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[39m#predictor.load_state_dict(torch.load(\"../weights/2023-04-12-20-02-45\",map_location=torch.device('cpu')).state_dict())\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../training_scripts/weights/2023-04-17-23-01-43'"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "predictor.load_state_dict(torch.load(\"../training_scripts/weights/2023-04-17-23-01-43\",map_location=torch.device('cpu')))\n",
    "predictor.eval()\n",
    "#predictor.load_state_dict(torch.load(\"../weights/2023-04-12-20-02-45\",map_location=torch.device('cpu')).state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 100\n",
    "\n",
    "timestamps = []\n",
    "for col in range(test_dataset.indices.shape[1]):\n",
    "    timestamps.append(list(test_data.iloc[sample_index:,col].dropna().index[:predictor.prediction_length]))\n",
    "\n",
    "timestamps = np.array(timestamps)\n",
    "\n",
    "samples = predictor.sample(\n",
    "    data = test_dataset,\n",
    "    sample_indices = timestamps,\n",
    "    num_samples = 100,\n",
    "    timestamp_encodings = encodings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n"
     ]
    }
   ],
   "source": [
    "realisations = []\n",
    "for col in range(test_dataset.indices.shape[1]):\n",
    "    realisations.append(test_dataset.data_copy.iloc[sample_index:,col].dropna()[:test_dataset.prediction_length])\n",
    "realisations = np.array(realisations)\n",
    "\n",
    "predictions = np.array(samples.cpu())\n",
    "\n",
    "# Calculate metrics\n",
    "var_score = variogram_score(realisations,predictions,**{\"weights\":\"local\",\"window_size\":5})\n",
    "crps_score = crps_sum(realisations,predictions)\n",
    "\n",
    "print(var_score,crps_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Plot the samples\u001b[39;00m\n\u001b[1;32m      2\u001b[0m confidence \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m samples_cpu \u001b[39m=\u001b[39m samples\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m      5\u001b[0m samples_cpu[:,\u001b[39m0\u001b[39m,:], _\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(samples_cpu[:,\u001b[39m0\u001b[39m,:],dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m samples_cpu[:,\u001b[39m1\u001b[39m,:], _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(samples_cpu[:,\u001b[39m1\u001b[39m,:],dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Plot the samples\n",
    "confidence = 0.1\n",
    "\n",
    "samples_cpu = samples.cpu().copy()\n",
    "samples_cpu[:,0,:], _= torch.sort(samples_cpu[:,0,:],dim=0)\n",
    "samples_cpu[:,1,:], _ = torch.sort(samples_cpu[:,1,:],dim=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_data.iloc[:sample_index,1].dropna().iloc[-predictor.context_length:],\"-x\")\n",
    "plt.plot(test_data.iloc[sample_index:,1].dropna().iloc[:predictor.prediction_length],\"-x\")\n",
    "plt.fill_between(timestamps[1], samples_cpu[int(confidence*samples_cpu.shape[0]),1,:], samples_cpu[int((1-confidence)*samples_cpu.shape[0]),1,:],alpha=0.5)\n",
    "plt.plot(timestamps[1],torch.mean(samples.cpu(),axis=0)[1],\"-o\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(val_data.data_copy.iloc[:sample_index,1].dropna().iloc[-predictor.context_length:],\"-x\")\n",
    "# plt.plot(val_data.data_copy.iloc[sample_index:,1].dropna().iloc[:predictor.prediction_length],\"-x\")\n",
    "# plt.fill_between(timestamps[1], samples_cpu[int(confidence*samples_cpu.shape[0]),1,:], samples_cpu[int((1-confidence)*samples_cpu.shape[0]),1,:],alpha=0.5)\n",
    "# plt.plot(timestamps[1],torch.mean(samples.cpu(),axis=0)[1],\"-o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4d8082ac81b5767605eb477108b3a93415a0db0c81fcb1a05e0921a30ce1269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from data import TimeFusionDataset\n",
    "from timefusion import TimeFusion\n",
    "from utils.metrics import variogram_score, crps_sum\n",
    "from utils.modules import EarlyStopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train_data = pd.read_csv(\"../datasets/electricity/train.csv\").set_index(\"date\")\n",
    "test_data = pd.read_csv(\"../datasets/electricity/test.csv\").set_index(\"date\")\n",
    "train_data = train_data.iloc[:,:20]\n",
    "test_data = test_data.iloc[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "    #device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 30\n",
    "prediction_length = 30\n",
    "\n",
    "# Create each dataset\n",
    "train_dataset = TimeFusionDataset(\n",
    "    data = train_data.iloc[:int(0.9*len(train_data))],\n",
    "    context_length = context_length,\n",
    ")\n",
    "\n",
    "val_dataset = TimeFusionDataset(\n",
    "    data = train_data.iloc[int(0.9*len(train_data)):],\n",
    "    context_length = context_length,\n",
    ")\n",
    "\n",
    "test_dataset = TimeFusionDataset(\n",
    "    data = test_data,\n",
    "    context_length = context_length,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    batch_size = 128,\n",
    "    #pin_memory=True,\n",
    "    #pin_memory_device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    batch_size = 128,\n",
    "    #pin_memory=True,\n",
    "    #pin_memory_device=\"cuda:0\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 81324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edvard/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/timefusion/diffusion.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.bar_alphas = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeFusion(\n",
    "    input_size = 20,\n",
    "    hidden_size = 60,\n",
    "    recurrent_layers = 2,\n",
    "    dropout = 0.0,\n",
    "    residual_layers = 2,\n",
    "    scaling = True,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "print(\"Number of trainable parameters:\",sum(p.numel() for p in predictor.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |==============================|  Batch: 170 / 170, Epoch: 1 / 40, Average Loss: 0.7800\n",
      " |==============================|  Batch: 170 / 170, Epoch: 2 / 40, Average Loss: 0.4436\n",
      " |============================= |  Batch: 168 / 170, Epoch: 3 / 40, Average Loss: 0.3874\r"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=predictor.parameters(),lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1, end_factor=0.01, total_iters=40)\n",
    "\n",
    "predictor.train_network(\n",
    "    train_loader = train_loader,\n",
    "    epochs=40,\n",
    "    val_loader = val_loader,\n",
    "    val_metrics= {\n",
    "        \"Val MAE\": nn.L1Loss(),\n",
    "    },\n",
    "    optimizer = optimizer,\n",
    "    lr_scheduler= lr_scheduler,\n",
    "    early_stopper=EarlyStopper(patience=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../training_scripts/weights/2023-04-17-23-01-43'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load weights\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictor\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39m../training_scripts/weights/2023-04-17-23-01-43\u001b[39;49m\u001b[39m\"\u001b[39;49m,map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m      3\u001b[0m predictor\u001b[39m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m \u001b[39m#predictor.load_state_dict(torch.load(\"../weights/2023-04-12-20-02-45\",map_location=torch.device('cpu')).state_dict())\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    271\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../training_scripts/weights/2023-04-17-23-01-43'"
     ]
    }
   ],
   "source": [
    "# Load weights\n",
    "predictor.load_state_dict(torch.load(\"../training_scripts/weights/2023-04-17-23-01-43\",map_location=torch.device('cpu')))\n",
    "predictor.eval()\n",
    "#predictor.load_state_dict(torch.load(\"../weights/2023-04-12-20-02-45\",map_location=torch.device('cpu')).state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 100\n",
    "\n",
    "timestamps = []\n",
    "for col in range(test_dataset.indices.shape[1]):\n",
    "    timestamps.append(list(test_data.iloc[sample_index:,col].dropna().index[:predictor.prediction_length]))\n",
    "\n",
    "timestamps = np.array(timestamps)\n",
    "\n",
    "samples = predictor.sample(\n",
    "    data = test_dataset,\n",
    "    sample_indices = timestamps,\n",
    "    num_samples = 100,\n",
    "    timestamp_encodings = encodings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n"
     ]
    }
   ],
   "source": [
    "realisations = []\n",
    "for col in range(test_dataset.indices.shape[1]):\n",
    "    realisations.append(test_dataset.data_copy.iloc[sample_index:,col].dropna()[:test_dataset.prediction_length])\n",
    "realisations = np.array(realisations)\n",
    "\n",
    "predictions = np.array(samples.cpu())\n",
    "\n",
    "# Calculate metrics\n",
    "var_score = variogram_score(realisations,predictions,**{\"weights\":\"local\",\"window_size\":5})\n",
    "crps_score = crps_sum(realisations,predictions)\n",
    "\n",
    "print(var_score,crps_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Plot the samples\u001b[39;00m\n\u001b[1;32m      2\u001b[0m confidence \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m samples_cpu \u001b[39m=\u001b[39m samples\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m      5\u001b[0m samples_cpu[:,\u001b[39m0\u001b[39m,:], _\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(samples_cpu[:,\u001b[39m0\u001b[39m,:],dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m samples_cpu[:,\u001b[39m1\u001b[39m,:], _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(samples_cpu[:,\u001b[39m1\u001b[39m,:],dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Plot the samples\n",
    "confidence = 0.1\n",
    "\n",
    "samples_cpu = samples.cpu().copy()\n",
    "samples_cpu[:,0,:], _= torch.sort(samples_cpu[:,0,:],dim=0)\n",
    "samples_cpu[:,1,:], _ = torch.sort(samples_cpu[:,1,:],dim=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_data.iloc[:sample_index,1].dropna().iloc[-predictor.context_length:],\"-x\")\n",
    "plt.plot(test_data.iloc[sample_index:,1].dropna().iloc[:predictor.prediction_length],\"-x\")\n",
    "plt.fill_between(timestamps[1], samples_cpu[int(confidence*samples_cpu.shape[0]),1,:], samples_cpu[int((1-confidence)*samples_cpu.shape[0]),1,:],alpha=0.5)\n",
    "plt.plot(timestamps[1],torch.mean(samples.cpu(),axis=0)[1],\"-o\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(val_data.data_copy.iloc[:sample_index,1].dropna().iloc[-predictor.context_length:],\"-x\")\n",
    "# plt.plot(val_data.data_copy.iloc[sample_index:,1].dropna().iloc[:predictor.prediction_length],\"-x\")\n",
    "# plt.fill_between(timestamps[1], samples_cpu[int(confidence*samples_cpu.shape[0]),1,:], samples_cpu[int((1-confidence)*samples_cpu.shape[0]),1,:],alpha=0.5)\n",
    "# plt.plot(timestamps[1],torch.mean(samples.cpu(),axis=0)[1],\"-o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4d8082ac81b5767605eb477108b3a93415a0db0c81fcb1a05e0921a30ce1269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set path to fix relative imports\n",
    "sys.path.append(\"..\")\n",
    "from data import TimeFusionDataset\n",
    "from timefusion import TimeFusion, EarlyStopper\n",
    "from metrics import variogram_score, crps_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "train_data = pd.read_csv(\"../../datasets/electricity/train.csv\").set_index(\"date\")\n",
    "test_data = pd.read_csv(\"../../datasets/electricity/test.csv\").set_index(\"date\")\n",
    "train_data = train_data.iloc[:,:30]\n",
    "test_data = test_data.iloc[:,:30]\n",
    "train_data.index = pd.to_datetime(train_data.index)\n",
    "test_data.index = pd.to_datetime(test_data.index)\n",
    "\n",
    "# Standardize data\n",
    "means = train_data.mean()\n",
    "stds = train_data.std()\n",
    "train_data = (train_data-means)/stds\n",
    "test_data = (test_data-means)/stds\n",
    "\n",
    "# Randomly remove 30% of data to make irregular\n",
    "np.random.seed(0) # Set random seed to make result reproducible\n",
    "#remove = 0.30\n",
    "remove = 0\n",
    "\n",
    "# Training data \n",
    "train_mask = np.full(train_data.size, False)\n",
    "train_mask[:int(train_data.size*remove)] = True\n",
    "np.random.shuffle(train_mask)\n",
    "train_data = train_data.mask(train_mask.reshape(train_data.shape))\n",
    "\n",
    "# Test data\n",
    "test_mask = np.full(test_data.size, False)\n",
    "test_mask[:int(test_data.size*remove)] = True\n",
    "np.random.shuffle(test_mask)\n",
    "test_data = test_data.mask(test_mask.reshape(test_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "    #device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some common variables\n",
    "context_length = 48 \n",
    "prediction_length = 24\n",
    "\n",
    "encodings = [\n",
    "    # lambda x: math.sin(2*math.pi*x.timestamp() / (3600*24)),\n",
    "    # lambda x: math.sin(2*math.pi*x.timestamp() / (3600*24*7)),\n",
    "    # lambda x: math.sin(2*math.pi*x.timestamp() / (3600*24*30)),\n",
    "    # lambda x: math.sin(2*math.pi*x.timestamp() / (3600*24*90)),\n",
    "    # lambda x: math.sin(2*math.pi*x.timestamp() / (3600*24*365)),\n",
    "    # lambda x: math.cos(2*math.pi*x.timestamp() / (3600*24)),\n",
    "    # lambda x: math.cos(2*math.pi*x.timestamp() / (3600*24*7)),\n",
    "    # lambda x: math.cos(2*math.pi*x.timestamp() / (3600*24*30)),\n",
    "    # lambda x: math.cos(2*math.pi*x.timestamp() / (3600*24*90)),\n",
    "    # lambda x: math.cos(2*math.pi*x.timestamp() / (3600*24*365)),\n",
    "]\n",
    "\n",
    "# Create each dataset\n",
    "train_dataset = TimeFusionDataset(\n",
    "    data = train_data.iloc[:int(0.9*len(train_data))],\n",
    "    context_length = context_length,\n",
    "    prediction_length = prediction_length,\n",
    "    timestamp_encodings = encodings\n",
    ")\n",
    "\n",
    "val_dataset = TimeFusionDataset(\n",
    "    data = train_data.iloc[int(0.9*len(train_data)):],\n",
    "    context_length = context_length,\n",
    "    prediction_length = prediction_length,\n",
    "    timestamp_encodings = encodings\n",
    ")\n",
    "\n",
    "test_dataset = TimeFusionDataset(\n",
    "    data = test_data,\n",
    "    context_length = context_length,\n",
    "    prediction_length = prediction_length,\n",
    "    timestamp_encodings = encodings\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    batch_size = 128,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=\"cuda:0\"\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset = val_dataset,\n",
    "    shuffle = True,\n",
    "    num_workers = 4,\n",
    "    batch_size = 128,\n",
    "    pin_memory=True,\n",
    "    pin_memory_device=\"cuda:0\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edvard/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/TimeFusion/visualisation_notebooks/../diffusion.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.bar_alphas = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "predictor = TimeFusion(\n",
    "    context_length = context_length,\n",
    "    prediction_length = prediction_length,\n",
    "    timeseries_shape = (len(train_dataset.time_series),train_dataset.time_series[0].shape[1]), \n",
    "    num_encoder_layers=3,\n",
    "    d_model=512,\n",
    "    nhead=32,\n",
    "    dim_feedforward=1024,\n",
    "    diff_steps=100,\n",
    "    device = device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeFusion(\n",
       "  (embedding): Linear(in_features=60, out_features=512, bias=True)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0, inplace=False)\n",
       "        (dropout2): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load weights\n",
    "predictor.load_state_dict(torch.load(\"../training_scripts/weights/2023-04-17-23-01-43\",map_location=torch.device('cpu')))\n",
    "predictor.eval()\n",
    "#predictor.load_state_dict(torch.load(\"../weights/2023-04-12-20-02-45\",map_location=torch.device('cpu')).state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 100\n",
    "\n",
    "timestamps = []\n",
    "for col in range(test_dataset.indices.shape[1]):\n",
    "    timestamps.append(list(test_data.iloc[sample_index:,col].dropna().index[:predictor.prediction_length]))\n",
    "\n",
    "timestamps = np.array(timestamps)\n",
    "\n",
    "samples = predictor.sample(\n",
    "    data = test_dataset,\n",
    "    sample_indices = timestamps,\n",
    "    num_samples = 100,\n",
    "    timestamp_encodings = encodings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan\n"
     ]
    }
   ],
   "source": [
    "realisations = []\n",
    "for col in range(test_dataset.indices.shape[1]):\n",
    "    realisations.append(test_dataset.data_copy.iloc[sample_index:,col].dropna()[:test_dataset.prediction_length])\n",
    "realisations = np.array(realisations)\n",
    "\n",
    "predictions = np.array(samples.cpu())\n",
    "\n",
    "# Calculate metrics\n",
    "var_score = variogram_score(realisations,predictions,**{\"weights\":\"local\",\"window_size\":5})\n",
    "crps_score = crps_sum(realisations,predictions)\n",
    "\n",
    "print(var_score,crps_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Plot the samples\u001b[39;00m\n\u001b[1;32m      2\u001b[0m confidence \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m samples_cpu \u001b[39m=\u001b[39m samples\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mcopy()\n\u001b[1;32m      5\u001b[0m samples_cpu[:,\u001b[39m0\u001b[39m,:], _\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(samples_cpu[:,\u001b[39m0\u001b[39m,:],dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m samples_cpu[:,\u001b[39m1\u001b[39m,:], _ \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msort(samples_cpu[:,\u001b[39m1\u001b[39m,:],dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Plot the samples\n",
    "confidence = 0.1\n",
    "\n",
    "samples_cpu = samples.cpu().copy()\n",
    "samples_cpu[:,0,:], _= torch.sort(samples_cpu[:,0,:],dim=0)\n",
    "samples_cpu[:,1,:], _ = torch.sort(samples_cpu[:,1,:],dim=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(test_data.iloc[:sample_index,1].dropna().iloc[-predictor.context_length:],\"-x\")\n",
    "plt.plot(test_data.iloc[sample_index:,1].dropna().iloc[:predictor.prediction_length],\"-x\")\n",
    "plt.fill_between(timestamps[1], samples_cpu[int(confidence*samples_cpu.shape[0]),1,:], samples_cpu[int((1-confidence)*samples_cpu.shape[0]),1,:],alpha=0.5)\n",
    "plt.plot(timestamps[1],torch.mean(samples.cpu(),axis=0)[1],\"-o\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(val_data.data_copy.iloc[:sample_index,1].dropna().iloc[-predictor.context_length:],\"-x\")\n",
    "# plt.plot(val_data.data_copy.iloc[sample_index:,1].dropna().iloc[:predictor.prediction_length],\"-x\")\n",
    "# plt.fill_between(timestamps[1], samples_cpu[int(confidence*samples_cpu.shape[0]),1,:], samples_cpu[int((1-confidence)*samples_cpu.shape[0]),1,:],alpha=0.5)\n",
    "# plt.plot(timestamps[1],torch.mean(samples.cpu(),axis=0)[1],\"-o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4d8082ac81b5767605eb477108b3a93415a0db0c81fcb1a05e0921a30ce1269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

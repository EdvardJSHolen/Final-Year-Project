{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch import DeepAREstimator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.torch.distributions import StudentTOutput\n",
    "from gluonts.torch.distributions import NormalOutput\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"D\"\n",
    "prediction_length = 30\n",
    "\n",
    "# Import dataset\n",
    "train_data = pd.read_csv(\"../datasets/exchange/train.csv\")\n",
    "val_data = pd.read_csv(\"../datasets/exchange/val.csv\")\n",
    "test_data = pd.read_csv(\"../datasets/exchange/test.csv\")\n",
    "\n",
    "dates = pd.date_range(start=\"1970-01-01\",periods = len(train_data) + len(val_data) + len(test_data), freq = freq)\n",
    "\n",
    "train_data.index = dates[:len(train_data)]\n",
    "val_data.index = dates[len(train_data):len(train_data) + len(val_data)]\n",
    "test_data.index = dates[len(train_data) + len(val_data):]\n",
    "\n",
    "# Normalize the signal power of each column\n",
    "stds = train_data.std()\n",
    "train_data /= stds\n",
    "val_data /= stds\n",
    "test_data /= stds\n",
    "\n",
    "# Get training, validation and test dataset\n",
    "train_flat = train_data.stack().reset_index()\n",
    "train_flat.columns = [\"date\", \"series\", \"value\"]\n",
    "train_dataset = PandasDataset.from_long_dataframe(train_flat, target=\"value\",item_id=\"series\",timestamp=\"date\",freq=freq)\n",
    "\n",
    "val_flat = val_data.stack().reset_index()\n",
    "val_flat.columns = [\"date\", \"series\", \"value\"]\n",
    "val_dataset = PandasDataset.from_long_dataframe(val_flat, target=\"value\",item_id=\"series\",timestamp=\"date\",freq=freq)\n",
    "val_dataset_14 = [PandasDataset.from_long_dataframe(val_flat.iloc[:-prediction_length*i*train_data.shape[1]] if i != 0 else val_flat, target=\"value\",item_id=\"series\",timestamp=\"date\",freq=freq) for i in range(14)]\n",
    "\n",
    "test_flat = val_data.stack().reset_index()\n",
    "test_flat.columns = [\"date\", \"series\", \"value\"]\n",
    "test_dataset_14 = [PandasDataset.from_long_dataframe(test_flat.iloc[:-prediction_length*i*train_data.shape[1]] if i != 0 else val_flat, target=\"value\",item_id=\"series\",timestamp=\"date\",freq=freq) for i in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and make predictions\n",
    "model = DeepAREstimator(\n",
    "    prediction_length = prediction_length, \n",
    "    freq=freq,\n",
    "    context_length = 1*prediction_length,\n",
    "    num_layers = 1,\n",
    "    hidden_size = 30,\n",
    "    lr = 1e-4,\n",
    "    dropout_rate = 0.01,\n",
    "    distr_output = NormalOutput(),\n",
    "    trainer_kwargs={\"max_epochs\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ejh19/home/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.01 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/rds/general/user/ejh19/home/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "/rds/general/user/ejh19/home/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name  | Type        | Params | In sizes | Out sizes   \n",
      "----------------------------------------------------------------\n",
      "0 | model | DeepARModel | 8.3 K  | ?        | [1, 100, 30]\n",
      "----------------------------------------------------------------\n",
      "8.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.3 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af4daa508fb44738ca4018f4d860556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f36701794f4264a0c2a397164be2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9c78f395494574bc045077d390867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'val_loss' reached 2.54597 (best 2.54597), saving model to '/rds/general/user/ejh19/home/Final-Year-Project/deepar/lightning_logs/version_11/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "predictor = model.train(training_data=train_dataset,validation_data=val_dataset,num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7281005382537842\n"
     ]
    }
   ],
   "source": [
    "# Validation test\n",
    "samples = []\n",
    "realisations = []\n",
    "\n",
    "start = time.time()\n",
    "for dataset in test_dataset_14:\n",
    "    \n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=dataset,\n",
    "        predictor=predictor,\n",
    "        num_samples=128\n",
    "    )\n",
    "\n",
    "    samples.append(list(forecast_it))\n",
    "    realisations.append(list(ts_it))\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepar",
   "language": "python",
   "name": "deepar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

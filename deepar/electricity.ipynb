{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch import DeepAREstimator\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from timefusion.utils import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_data = pd.read_csv(\"../datasets/electricity/train.csv\", index_col=\"date\")\n",
    "val_data = pd.read_csv(\"../datasets/electricity/val.csv\", index_col=\"date\")\n",
    "test_data = pd.read_csv(\"../datasets/electricity/test.csv\", index_col=\"date\")\n",
    "\n",
    "# Normalize data standard deviation\n",
    "stds = train_data.std()\n",
    "train_data /= stds\n",
    "val_data /= stds\n",
    "test_data /= stds\n",
    "\n",
    "# Some parameters\n",
    "prediction_length = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PandasDataset.__init__() got an unexpected keyword argument 'item_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m new_data \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mstack()\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      3\u001b[0m new_data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m new_dataset \u001b[39m=\u001b[39m PandasDataset(new_data, target\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,item_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mseries\u001b[39;49m\u001b[39m\"\u001b[39;49m,timestamp\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m\"\u001b[39;49m,freq\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mH\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: PandasDataset.__init__() got an unexpected keyword argument 'item_id'"
     ]
    }
   ],
   "source": [
    "# Flatten pandas dataframe and add column names in new column\n",
    "new_data = train_data.stack().reset_index()\n",
    "new_data.columns = [\"date\", \"series\", \"value\"]\n",
    "new_dataset = PandasDataset(new_data, target=\"value\",item_id=\"series\",timestamp=\"date\",freq=\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = PandasDataset(train_data, target=train_data.columns,freq=\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/edvard/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "/Users/edvard/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/configuration_validator.py:72: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /Users/edvard/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/lightning_logs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Multi-layer LSTM support in MPS available only on MacOS 13 onwards",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m test_data \u001b[39m=\u001b[39m test_gen\u001b[39m.\u001b[39mgenerate_instances(prediction_length\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m, windows\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Train the model and make predictions\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model \u001b[39m=\u001b[39m DeepAREstimator(\n\u001b[1;32m      7\u001b[0m     prediction_length\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m, freq\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mM\u001b[39;49m\u001b[39m\"\u001b[39;49m, trainer_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mmax_epochs\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m5\u001b[39;49m}\n\u001b[0;32m----> 8\u001b[0m )\u001b[39m.\u001b[39;49mtrain(training_data)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/gluonts/torch/model/estimator.py:237\u001b[0m, in \u001b[0;36mPyTorchLightningEstimator.train\u001b[0;34m(self, training_data, validation_data, shuffle_buffer_length, cache_data, ckpt_path, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    230\u001b[0m     training_data: Dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    236\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PyTorchPredictor:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_model(\n\u001b[1;32m    238\u001b[0m         training_data,\n\u001b[1;32m    239\u001b[0m         validation_data,\n\u001b[1;32m    240\u001b[0m         shuffle_buffer_length\u001b[39m=\u001b[39;49mshuffle_buffer_length,\n\u001b[1;32m    241\u001b[0m         cache_data\u001b[39m=\u001b[39;49mcache_data,\n\u001b[1;32m    242\u001b[0m         ckpt_path\u001b[39m=\u001b[39;49mckpt_path,\n\u001b[1;32m    243\u001b[0m     )\u001b[39m.\u001b[39mpredictor\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/gluonts/torch/model/estimator.py:205\u001b[0m, in \u001b[0;36mPyTorchLightningEstimator.train_model\u001b[0;34m(self, training_data, validation_data, from_predictor, shuffle_buffer_length, cache_data, ckpt_path, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m trainer_kwargs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer_kwargs, \u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m: callbacks}\n\u001b[1;32m    203\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_kwargs)\n\u001b[0;32m--> 205\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    206\u001b[0m     model\u001b[39m=\u001b[39;49mtraining_network,\n\u001b[1;32m    207\u001b[0m     train_dataloaders\u001b[39m=\u001b[39;49mtraining_data_loader,\n\u001b[1;32m    208\u001b[0m     val_dataloaders\u001b[39m=\u001b[39;49mvalidation_data_loader,\n\u001b[1;32m    209\u001b[0m     ckpt_path\u001b[39m=\u001b[39;49mckpt_path,\n\u001b[1;32m    210\u001b[0m )\n\u001b[1;32m    212\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading best model from \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint\u001b[39m.\u001b[39mbest_model_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    213\u001b[0m best_model \u001b[39m=\u001b[39m training_network\u001b[39m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m    214\u001b[0m     checkpoint\u001b[39m.\u001b[39mbest_model_path\n\u001b[1;32m    215\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    521\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    522\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    561\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:915\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n\u001b[0;32m--> 915\u001b[0m     call\u001b[39m.\u001b[39;49m_call_callback_hooks(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mon_fit_start\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    916\u001b[0m     call\u001b[39m.\u001b[39m_call_lightning_module_hook(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mon_fit_start\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    918\u001b[0m _log_hyperparams(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:190\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(fn):\n\u001b[1;32m    189\u001b[0m         \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 190\u001b[0m             fn(trainer, trainer\u001b[39m.\u001b[39;49mlightning_module, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    192\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[1;32m    193\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_summary.py:59\u001b[0m, in \u001b[0;36mModelSummary.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_depth:\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m model_summary \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_summary(trainer, pl_module)\n\u001b[1;32m     60\u001b[0m summary_data \u001b[39m=\u001b[39m model_summary\u001b[39m.\u001b[39m_get_summary_data()\n\u001b[1;32m     61\u001b[0m total_parameters \u001b[39m=\u001b[39m model_summary\u001b[39m.\u001b[39mtotal_parameters\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_summary.py:73\u001b[0m, in \u001b[0;36mModelSummary._summary\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(trainer\u001b[39m.\u001b[39mstrategy, DeepSpeedStrategy) \u001b[39mand\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mzero_stage_3:\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m DeepSpeedSummary(pl_module, max_depth\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_depth)\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m summarize(pl_module, max_depth\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_max_depth)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:431\u001b[0m, in \u001b[0;36msummarize\u001b[0;34m(lightning_module, max_depth)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msummarize\u001b[39m(lightning_module: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m, max_depth: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ModelSummary:\n\u001b[1;32m    420\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Summarize the LightningModule specified by `lightning_module`.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[1;32m    422\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m        The model summary object\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     \u001b[39mreturn\u001b[39;00m ModelSummary(lightning_module, max_depth\u001b[39m=\u001b[39;49mmax_depth)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:189\u001b[0m, in \u001b[0;36mModelSummary.__init__\u001b[0;34m(self, model, max_depth)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`max_depth` can be -1, 0 or > 0, got \u001b[39m\u001b[39m{\u001b[39;00mmax_depth\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_depth \u001b[39m=\u001b[39m max_depth\n\u001b[0;32m--> 189\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layer_summary \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msummarize()\n\u001b[1;32m    190\u001b[0m \u001b[39m# 1 byte -> 8 bits\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[39m# TODO: how do we compute precision_megabytes in case of mixed precision?\u001b[39;00m\n\u001b[1;32m    192\u001b[0m precision_to_bits \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39m64\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m64\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m32\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m32\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m16\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m16\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbf16\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m16\u001b[39m}\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:246\u001b[0m, in \u001b[0;36mModelSummary.summarize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m summary \u001b[39m=\u001b[39m OrderedDict((name, LayerSummary(module)) \u001b[39mfor\u001b[39;00m name, module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_modules)\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mexample_input_array \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_example_input()\n\u001b[1;32m    247\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m summary\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    248\u001b[0m     layer\u001b[39m.\u001b[39mdetach_hook()\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:276\u001b[0m, in \u001b[0;36mModelSummary._forward_example_input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m     model(\u001b[39m*\u001b[39minput_)\n\u001b[1;32m    275\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(input_, \u001b[39mdict\u001b[39m):\n\u001b[0;32m--> 276\u001b[0m     model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minput_)\n\u001b[1;32m    277\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     model(input_)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/gluonts/torch/model/deepar/lightning_module.py:68\u001b[0m, in \u001b[0;36mDeepARLightningModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/gluonts/torch/model/deepar/module.py:393\u001b[0m, in \u001b[0;36mDeepARModel.forward\u001b[0;34m(self, feat_static_cat, feat_static_real, past_time_feat, past_target, past_observed_values, future_time_feat, num_parallel_samples)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m num_parallel_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     num_parallel_samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_parallel_samples\n\u001b[0;32m--> 393\u001b[0m params, scale, _, static_feat, state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munroll_lagged_rnn(\n\u001b[1;32m    394\u001b[0m     feat_static_cat,\n\u001b[1;32m    395\u001b[0m     feat_static_real,\n\u001b[1;32m    396\u001b[0m     past_time_feat,\n\u001b[1;32m    397\u001b[0m     past_target,\n\u001b[1;32m    398\u001b[0m     past_observed_values,\n\u001b[1;32m    399\u001b[0m     future_time_feat[:, :\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    400\u001b[0m )\n\u001b[1;32m    402\u001b[0m repeated_scale \u001b[39m=\u001b[39m scale\u001b[39m.\u001b[39mrepeat_interleave(\n\u001b[1;32m    403\u001b[0m     repeats\u001b[39m=\u001b[39mnum_parallel_samples, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    404\u001b[0m )\n\u001b[1;32m    405\u001b[0m repeated_static_feat \u001b[39m=\u001b[39m static_feat\u001b[39m.\u001b[39mrepeat_interleave(\n\u001b[1;32m    406\u001b[0m     repeats\u001b[39m=\u001b[39mnum_parallel_samples, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    407\u001b[0m )\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/gluonts/torch/model/deepar/module.py:321\u001b[0m, in \u001b[0;36mDeepARModel.unroll_lagged_rnn\u001b[0;34m(self, feat_static_cat, feat_static_real, past_time_feat, past_target, past_observed_values, future_time_feat, future_target)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39mApplies the underlying RNN to the provided target data and covariates.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[39m    - Output state from the RNN\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    311\u001b[0m rnn_input, scale, static_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_rnn_input(\n\u001b[1;32m    312\u001b[0m     feat_static_cat,\n\u001b[1;32m    313\u001b[0m     feat_static_real,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m     future_target,\n\u001b[1;32m    319\u001b[0m )\n\u001b[0;32m--> 321\u001b[0m output, new_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(rnn_input)\n\u001b[1;32m    323\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_proj(output)\n\u001b[1;32m    324\u001b[0m \u001b[39mreturn\u001b[39;00m params, scale, output, static_feat, new_state\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Multi-layer LSTM support in MPS available only on MacOS 13 onwards"
     ]
    }
   ],
   "source": [
    "# Split the data for training and testing\n",
    "training_data, test_gen = split(k, offset=-36)\n",
    "test_data = test_gen.generate_instances(prediction_length=12, windows=3)\n",
    "\n",
    "# Train the model and make predictions\n",
    "model = DeepAREstimator(\n",
    "    prediction_length=12, freq=\"M\", trainer_kwargs={\"max_epochs\": 5}\n",
    ").train(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = list(model.predict(test_data.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PandasDataset.from_long_dataframe(train_data, target='sales', item_id='family', \n",
    "                                       timestamp='date', freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>series</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>3.474225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>5.483391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>3.516469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>4.178658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522588</th>\n",
       "      <td>2014-05-01 23:00:00</td>\n",
       "      <td>364</td>\n",
       "      <td>1.327435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522589</th>\n",
       "      <td>2014-05-01 23:00:00</td>\n",
       "      <td>365</td>\n",
       "      <td>1.251796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522590</th>\n",
       "      <td>2014-05-01 23:00:00</td>\n",
       "      <td>366</td>\n",
       "      <td>5.533703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522591</th>\n",
       "      <td>2014-05-01 23:00:00</td>\n",
       "      <td>367</td>\n",
       "      <td>2.302554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522592</th>\n",
       "      <td>2014-05-01 23:00:00</td>\n",
       "      <td>368</td>\n",
       "      <td>4.930852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6522593 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date series     value\n",
       "0        2012-01-01 01:00:00      0  0.597613\n",
       "1        2012-01-01 01:00:00      1  3.474225\n",
       "2        2012-01-01 01:00:00      2  5.483391\n",
       "3        2012-01-01 01:00:00      3  3.516469\n",
       "4        2012-01-01 01:00:00      4  4.178658\n",
       "...                      ...    ...       ...\n",
       "6522588  2014-05-01 23:00:00    364  1.327435\n",
       "6522589  2014-05-01 23:00:00    365  1.251796\n",
       "6522590  2014-05-01 23:00:00    366  5.533703\n",
       "6522591  2014-05-01 23:00:00    367  2.302554\n",
       "6522592  2014-05-01 23:00:00    368  4.930852\n",
       "\n",
       "[6522593 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (319,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data\u001b[39m.\u001b[39;49mpivot(columns\u001b[39m=\u001b[39;49mtrain_data\u001b[39m.\u001b[39;49mcolumns)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/frame.py:8414\u001b[0m, in \u001b[0;36mDataFrame.pivot\u001b[0;34m(self, columns, index, values)\u001b[0m\n\u001b[1;32m   8409\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8410\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   8411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, columns, index\u001b[39m=\u001b[39mlib\u001b[39m.\u001b[39mNoDefault, values\u001b[39m=\u001b[39mlib\u001b[39m.\u001b[39mNoDefault) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   8412\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot\n\u001b[0;32m-> 8414\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot(\u001b[39mself\u001b[39;49m, index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns, values\u001b[39m=\u001b[39;49mvalues)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/reshape/pivot.py:528\u001b[0m, in \u001b[0;36mpivot\u001b[0;34m(data, columns, index, values)\u001b[0m\n\u001b[1;32m    524\u001b[0m     append \u001b[39m=\u001b[39m index \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mNoDefault\n\u001b[1;32m    525\u001b[0m     \u001b[39m# error: Unsupported operand types for + (\"List[Any]\" and \"ExtensionArray\")\u001b[39;00m\n\u001b[1;32m    526\u001b[0m     \u001b[39m# error: Unsupported left operand type for + (\"ExtensionArray\")\u001b[39;00m\n\u001b[1;32m    527\u001b[0m     indexed \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mset_index(\n\u001b[0;32m--> 528\u001b[0m         cols \u001b[39m+\u001b[39;49m columns_listlike, append\u001b[39m=\u001b[39mappend  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    531\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mNoDefault:\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/arraylike.py:190\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__radd__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__radd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mradd)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6814\u001b[0m, in \u001b[0;36mIndex._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6804\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   6805\u001b[0m     \u001b[39misinstance\u001b[39m(other, Index)\n\u001b[1;32m   6806\u001b[0m     \u001b[39mand\u001b[39;00m is_object_dtype(other\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6810\u001b[0m     \u001b[39m# a chance to implement ops before we unwrap them.\u001b[39;00m\n\u001b[1;32m   6811\u001b[0m     \u001b[39m# See https://github.com/pandas-dev/pandas/issues/31109\u001b[39;00m\n\u001b[1;32m   6812\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m-> 6814\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_arith_method(other, op)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1345\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[1;32m   1347\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1348\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[1;32m   1350\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m    230\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    168\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[1;32m    170\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[1;32m    172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[1;32m    174\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[1;32m    175\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[1;32m    176\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    177\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/computation/expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/computation/expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[1;32m     69\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "File \u001b[0;32m~/Documents/Imperial College/Year 4/Final Year Project/Final-Year-Project/deepar/.venv/lib/python3.10/site-packages/pandas/core/roperator.py:11\u001b[0m, in \u001b[0;36mradd\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradd\u001b[39m(left, right):\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m+\u001b[39;49m left\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (319,) "
     ]
    }
   ],
   "source": [
    "train_data.pivot(columns=train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PandasDataset(\n",
    "    train_data,\n",
    "    target="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.42809645346403336 0.5037136108854312 0.4162448194311368 78.30510365282612 0.12931775661936545\n",
      "2 0.33741997265193774 0.4326887075433596 0.34147022973514995 48.611834718694695 0.11728394631300333\n",
      "4 0.3348306441558083 0.4316285149086197 0.33842160591304704 52.447653252223084 0.11276774423632414\n",
      "8 0.29316377267101074 0.3903048875443268 0.29005621017771865 28.269334931856907 0.10805193984487983\n",
      "16 0.30094982988254454 0.391862092974616 0.2855206266153585 39.21508338970704 0.10772115789238683\n",
      "32 0.43851576342307963 0.48588394598339224 0.36437633821310755 30.968111362522855 0.147259184528114\n",
      "64 320.69901703605007 13.30320995427674 10.206449440930175 1044.2206077181154 11.464323262676938\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(val_data.shape[0] - prediction_length, val_data.shape[0] - prediction_length - 14*prediction_length, - prediction_length))\n",
    "realisations = torch.tensor(np.array([val_data.values[idx:idx+prediction_length] for idx in indices])).permute((0,2,1))\n",
    "\n",
    "# Find best lag order using validation data\n",
    "for i in range(9):\n",
    "    maxlags = 2**i\n",
    "    model = VAR(train_data, freq=\"H\")\n",
    "    results = model.fit(maxlags=maxlags)\n",
    "\n",
    "    # Test on validation data\n",
    "    samples = []\n",
    "    for idx in indices:\n",
    "        predictions = results.forecast(val_data.values[idx-maxlags:idx], prediction_length)\n",
    "        samples.append(torch.tensor(predictions).T)\n",
    "    samples = torch.stack(samples)\n",
    "\n",
    "    # Compute metrics\n",
    "    mse = mean_squared_error(realisations.flatten(), samples.flatten())\n",
    "    mae = mean_absolute_error(realisations.flatten(), samples.flatten())\n",
    "    mdae = median_absolute_error(realisations.flatten(), samples.flatten())\n",
    "    crps_sum = np.mean([metrics.crps_sum(samples[i].unsqueeze(0), realisations[i]) for i in range(realisations.shape[0])])\n",
    "    variogram_score = np.mean([metrics.variogram_score(samples[i].unsqueeze(0), realisations[i], weights=\"local\", window_size=2) for i in range(realisations.shape[0])])\n",
    "    print(maxlags, mse, mae, mdae, crps_sum, variogram_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.2370868538876482 0.3698434929681436 0.2941041310678142 39.73870525246162 0.09652434138596963\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "indices = list(range(test_data.shape[0] - prediction_length, test_data.shape[0] - prediction_length - 14*prediction_length, - prediction_length))\n",
    "realisations = torch.tensor(np.array([test_data.values[idx:idx+prediction_length] for idx in indices])).permute((0,2,1))\n",
    "\n",
    "maxlags = 16\n",
    "model = VAR(train_data, freq=\"H\")\n",
    "results = model.fit(maxlags=maxlags)\n",
    "\n",
    "samples = []\n",
    "for idx in indices:\n",
    "    predictions = results.forecast(test_data.values[idx-maxlags:idx], prediction_length)\n",
    "    samples.append(torch.tensor(predictions).T)\n",
    "samples = torch.stack(samples)\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(realisations.flatten(), samples.flatten())\n",
    "mae = mean_absolute_error(realisations.flatten(), samples.flatten())\n",
    "mdae = median_absolute_error(realisations.flatten(), samples.flatten())\n",
    "crps_sum = np.mean([metrics.crps_sum(samples[i].unsqueeze(0), realisations[i]) for i in range(realisations.shape[0])])\n",
    "variogram_score = np.mean([metrics.variogram_score(samples[i].unsqueeze(0), realisations[i], weights=\"local\", window_size=2) for i in range(realisations.shape[0])])\n",
    "print(maxlags, mse, mae, mdae, crps_sum, variogram_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_data = pd.read_csv(\"../datasets/exchange/train.csv\")\n",
    "val_data = pd.read_csv(\"../datasets/exchange/val.csv\")\n",
    "test_data = pd.read_csv(\"../datasets/exchange/test.csv\")\n",
    "\n",
    "# Normalize the signal power of each column\n",
    "stds = train_data.std()\n",
    "train_data /= stds\n",
    "val_data /= stds\n",
    "test_data /= stds\n",
    "\n",
    "# Some parameters\n",
    "prediction_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.016887865244289584 0.08285313547978906 0.05705872776203247 0.3875437108550224 0.007100809866249035\n",
      "2 0.01600563017641964 0.08044273913772125 0.055898168412147786 0.39755590904899546 0.006611613659898859\n",
      "4 0.01590528870426354 0.08038796570215245 0.05603026165879221 0.40289661524336184 0.006757353077013506\n",
      "8 0.016255463089877683 0.08148263063959078 0.055387505138935644 0.40420081397144525 0.00682316228610307\n",
      "16 0.016890449324062723 0.08352513982132848 0.05839952420968331 0.3928941018252983 0.007186250230818358\n",
      "32 0.017348761068782945 0.08499863718211402 0.059467347076881616 0.4203400007524149 0.00730509482813132\n",
      "64 0.018445937495137472 0.08971356049586499 0.06483874747782226 0.43286799068109894 0.008342773692809\n",
      "128 0.02308240927641897 0.10339533717536958 0.07781495882099909 0.44621025599620834 0.010199360586690215\n",
      "256 0.0349718814716449 0.12775029740485672 0.09355699615764612 0.5278636048292684 0.012212015622223734\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(val_data.shape[0] - prediction_length, val_data.shape[0] - prediction_length - 14*prediction_length, - prediction_length))\n",
    "realisations = torch.tensor(np.array([val_data.values[idx:idx+prediction_length] for idx in indices])).permute((0,2,1))\n",
    "\n",
    "# Find best lag order using validation data\n",
    "for i in range(9):\n",
    "    maxlags = 2**i\n",
    "    model = VAR(train_data)\n",
    "    results = model.fit(maxlags=maxlags)\n",
    "\n",
    "    # Test on validation data\n",
    "    samples = []\n",
    "    for idx in indices:\n",
    "        predictions = results.forecast(val_data.values[idx-maxlags:idx], prediction_length)\n",
    "        samples.append(torch.tensor(predictions).T)\n",
    "    samples = torch.stack(samples)\n",
    "\n",
    "    # Compute metrics\n",
    "    mse = mean_squared_error(realisations.flatten(), samples.flatten())\n",
    "    mae = mean_absolute_error(realisations.flatten(), samples.flatten())\n",
    "    mdae = median_absolute_error(realisations.flatten(), samples.flatten())\n",
    "    crps_sum = np.mean([metrics.crps_sum(samples[i].unsqueeze(0), realisations[i]) for i in range(realisations.shape[0])])\n",
    "    variogram_score = np.mean([metrics.variogram_score(samples[i].unsqueeze(0), realisations[i], weights=\"local\", window_size=2) for i in range(realisations.shape[0])])\n",
    "    print(maxlags, mse, mae, mdae, crps_sum, variogram_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.02264539828816738 0.10316918016684003 0.07164596930846923 0.5658821770696283 0.009198252098755463\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "indices = list(range(test_data.shape[0] - prediction_length, test_data.shape[0] - prediction_length - 14*prediction_length, - prediction_length))\n",
    "realisations = torch.tensor(np.array([test_data.values[idx:idx+prediction_length] for idx in indices])).permute((0,2,1))\n",
    "\n",
    "maxlags = 2\n",
    "model = VAR(train_data)\n",
    "results = model.fit(maxlags=maxlags)\n",
    "\n",
    "samples = []\n",
    "for idx in indices:\n",
    "    predictions = results.forecast(test_data.values[idx-maxlags:idx], prediction_length)\n",
    "    samples.append(torch.tensor(predictions).T)\n",
    "samples = torch.stack(samples)\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(realisations.flatten(), samples.flatten())\n",
    "mae = mean_absolute_error(realisations.flatten(), samples.flatten())\n",
    "mdae = median_absolute_error(realisations.flatten(), samples.flatten())\n",
    "crps_sum = np.mean([metrics.crps_sum(samples[i].unsqueeze(0), realisations[i]) for i in range(realisations.shape[0])])\n",
    "variogram_score = np.mean([metrics.variogram_score(samples[i].unsqueeze(0), realisations[i], weights=\"local\", window_size=2) for i in range(realisations.shape[0])])\n",
    "print(maxlags, mse, mae, mdae, crps_sum, variogram_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../datasets/solar/train.csv\", index_col=\"LocalTime\")\n",
    "val_data = pd.read_csv(\"../datasets/solar/val.csv\", index_col=\"LocalTime\")\n",
    "test_data = pd.read_csv(\"../datasets/solar/test.csv\", index_col=\"LocalTime\")\n",
    "\n",
    "# Normalize the signal power of each column\n",
    "stds = train_data.std()\n",
    "train_data /= stds\n",
    "val_data /= stds\n",
    "test_data /= stds\n",
    "\n",
    "# Some parameters\n",
    "prediction_length = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.747472462482723 0.6998342341962218 0.6485854361559291 93.5627800741968 0.1292754332383914\n",
      "2 0.6849015885095434 0.6649527929845294 0.6148021790995875 88.38290055292362 0.11043431932795945\n",
      "4 0.616923598002049 0.612875709890228 0.5030629824558094 80.80328673138362 0.11340872921981952\n",
      "8 0.4294411478493363 0.5079374355569413 0.39868764346455754 66.16652101183354 0.12165627854076758\n",
      "16 0.18786273542706916 0.3051231158531769 0.22002305778954429 38.20234638453345 0.0935745133534021\n",
      "32 0.23727260781902831 0.3298026001645596 0.2075377920066261 35.95539817484711 0.16208593626150886\n",
      "64 0.8935950611997517 0.7095407398978686 0.5377350766005918 72.36272555254483 0.4589726460094808\n",
      "128 0.19365192504008913 0.3027622832364533 0.20533938167854202 31.76083669868841 0.1474379142634344\n",
      "256 0.1456419727746064 0.24729169478599491 0.14717721127324013 24.785998286676136 0.12111754803348981\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(val_data.shape[0] - prediction_length, val_data.shape[0] - prediction_length - 14*prediction_length, - prediction_length))\n",
    "realisations = torch.tensor(np.array([val_data.values[idx:idx+prediction_length] for idx in indices])).permute((0,2,1))\n",
    "\n",
    "# Find best lag order using validation data\n",
    "for i in range(9):\n",
    "    maxlags = 2**i\n",
    "    model = VAR(train_data, freq=\"H\")\n",
    "    results = model.fit(maxlags=maxlags)\n",
    "\n",
    "    # Test on validation data\n",
    "    samples = []\n",
    "    for idx in indices:\n",
    "        predictions = results.forecast(val_data.values[idx-maxlags:idx], prediction_length)\n",
    "        samples.append(torch.tensor(predictions).T)\n",
    "    samples = torch.stack(samples)\n",
    "\n",
    "    # Compute metrics\n",
    "    mse = mean_squared_error(realisations.flatten(), samples.flatten())\n",
    "    mae = mean_absolute_error(realisations.flatten(), samples.flatten())\n",
    "    mdae = median_absolute_error(realisations.flatten(), samples.flatten())\n",
    "    crps_sum = np.mean([metrics.crps_sum(samples[i].unsqueeze(0), realisations[i]) for i in range(realisations.shape[0])])\n",
    "    variogram_score = np.mean([metrics.variogram_score(samples[i].unsqueeze(0), realisations[i], weights=\"local\", window_size=2) for i in range(realisations.shape[0])])\n",
    "    print(maxlags, mse, mae, mdae, crps_sum, variogram_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0.2921837702543927 0.4064584723453067 0.28972340584731704 51.25028968520726 0.10033451264590383\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "indices = list(range(test_data.shape[0] - prediction_length, test_data.shape[0] - prediction_length - 14*prediction_length, - prediction_length))\n",
    "realisations = torch.tensor(np.array([test_data.values[idx:idx+prediction_length] for idx in indices])).permute((0,2,1))\n",
    "\n",
    "maxlags = 16\n",
    "model = VAR(train_data, freq=\"H\")\n",
    "results = model.fit(maxlags=maxlags)\n",
    "\n",
    "samples = []\n",
    "for idx in indices:\n",
    "    predictions = results.forecast(test_data.values[idx-maxlags:idx], prediction_length)\n",
    "    samples.append(torch.tensor(predictions).T)\n",
    "samples = torch.stack(samples)\n",
    "\n",
    "# Compute metrics\n",
    "mse = mean_squared_error(realisations.flatten(), samples.flatten())\n",
    "mae = mean_absolute_error(realisations.flatten(), samples.flatten())\n",
    "mdae = median_absolute_error(realisations.flatten(), samples.flatten())\n",
    "crps_sum = np.mean([metrics.crps_sum(samples[i].unsqueeze(0), realisations[i]) for i in range(realisations.shape[0])])\n",
    "variogram_score = np.mean([metrics.variogram_score(samples[i].unsqueeze(0), realisations[i], weights=\"local\", window_size=2) for i in range(realisations.shape[0])])\n",
    "print(maxlags, mse, mae, mdae, crps_sum, variogram_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep3.10",
   "language": "python",
   "name": "deep3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
